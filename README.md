[![LICENSE](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/sebasmos/quantaudio/blob/main/LICENSE)
[![Python Version](https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12-blue.svg)](https://github.com/sebasmos/quantaudio)

# QuantAudio: Optimized Pre-Trained Vector Embeddings for Resource-Efficient Audio Classification

> ğŸš§ This repository is under development.
>
> ğŸ“© **Code and models will be made publicly available upon preprint upload or journal submission.**

- ğŸ“‚ **GitHub Repository**: [quantaudio](https://github.com/sebasmos/quantaudio)

## Project Structure

- ğŸ“ `data/` â€“ Links and scripts to download UrbanSound8K, ESC-50, and other datasets
- ğŸ“ `src/`
  - `preprocessing/` â€“ Audio loading, Mel spectrogram generation
  - `models/` â€“ Embedding extractor, MLP classifier
  - `quantization/` â€“ Post-training quantization scripts
  - `evaluation/` â€“ Metrics and logging tools
- ğŸ“ `experiments/` â€“ Configs and logs for reproducible experiments
- ğŸ“ `notebooks/` â€“ Visualizations and exploratory analyses
- ğŸ“ `scripts/` â€“ End-to-end training, testing, and quantization pipelines

QVE/
â”œâ”€â”€ data/                         # Data files and processed data
â”‚   â”œâ”€â”€ esc/                      # ESC dataset (raw/processed data)
â”‚   â”œâ”€â”€ urban8k/                  # Urban8K dataset (raw/processed data)
â”‚   â””â”€â”€ data_processing.py        # Functions to load and preprocess datasets
â”œâ”€â”€ qve/                          # Main module (QVE)
â”‚   â”œâ”€â”€ model.py                  # Model definition
â”‚   â”œâ”€â”€ trainer.py                # PyTorch Lightning training loop
â”‚   â”œâ”€â”€ utils.py                  # Utility functions
â”œâ”€â”€ scripts/                      # Standalone scripts
â”‚   â”œâ”€â”€ run_training.py           # Start training process
â”‚   â”œâ”€â”€ cross_validation.py       # Run cross-validation with different datasets
â”‚   â””â”€â”€ test.py                   # Testing the model
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â””â”€â”€ experiment_config.yaml    # Central config file (datasets, hyperparameters, training params)
â”œâ”€â”€ LICENSE                       # License
â”œâ”€â”€ README.md                     # Project documentation
â””â”€â”€ requirements.txt              # Dependencies

## Setting Up Your Environment

1. **Create a Conda Environment:**
   ```bash
   conda create -n quantaudio python=3.11 -y
   conda activate quantaudio
   ```

2. **Install Dependencies:**
   ```bash
   git clone https://github.com/sebasmos/quantaudio.git
   cd quantaudio
   pip install -r requirements.txt
   ```

## Running the Pipeline

To train and evaluate the quantized MLP classifier:
```bash
python scripts/train.py --config configs/urban8k_base.yaml
```

To apply post-training quantization:
```bash
python scripts/quantize.py --model-checkpoint checkpoints/best_model.pth
```

## Contributing to QuantAudio

We welcome community contributions! Fork the [QuantAudio repository](https://github.com/sebasmos/QuantAudio), make your improvements, and open a pull request. Contributors will be acknowledged in the release.

Feel free to report bugs, suggest features, or share your use cases.

## License

QuantAudio is **free** and **open source**, released under the [MIT License](https://github.com/sebasmos/QuantAudio/blob/main/LICENSE).

## Citation

```bibtex
@software{Cajas2025_QuantAudio,
  author = {Cajas Ord\'o\~nez, Sebasti\'an Andr\'es and Torres Torres, Luis Fernando and Bosch, Cristian and Lai, Yuan and Duran Paredes, Carlos Andr\'es and Celi, Leo Anthony and Simon Carbajo, Ricardo},
  title = {QuantAudio: Optimized Pre-Trained Vector Embeddings for Resource-Efficient Audio Classification},
  year = {2025},
  url = {https://github.com/sebasmos/QuantAudio},
  license = {MIT}
}
```
