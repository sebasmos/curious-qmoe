#!/usr/bin/env python3
"""
Generate rebuttal confidence distribution figure.

Usage:
    python generate_rebuttal_figure.py \
        --routing-json ../analysis/outputs-0.2/rebuttal_routing/routing_results.json \
        --output ../docs-temp/rebuttal_confidence_distribution.pdf

Output:
    - PDF figure showing confidence distribution by expert
    - Box plots with means indicated by dashed lines
    - Statistical annotation (p<0.001)
"""

import argparse
import json
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats


def load_routing_data(json_path):
    """Load routing results from JSON file."""
    with open(json_path, 'r') as f:
        data = json.load(f)
    return data


def extract_confidence_by_expert(data):
    """Extract confidence values grouped by expert."""
    confidence_by_expert = {}

    # Use full routing data if available, otherwise use summaries
    if 'routing' in data and len(data['routing']) > 0:
        for sample in data['routing']:
            expert_id = sample['expert']
            confidence = sample['confidence']

            if expert_id not in confidence_by_expert:
                confidence_by_expert[expert_id] = []
            confidence_by_expert[expert_id].append(confidence)

    # Also get summaries for full dataset statistics
    summaries = data.get('summaries', {})

    return confidence_by_expert, summaries


def compute_statistical_test(confidence_by_expert):
    """Compute t-test comparing Q8 (expert 2) against others."""
    # Get Q8 confidence values
    q8_conf = confidence_by_expert.get(2, [])

    # Get BitNet and Q4 confidence values
    others_conf = (
        confidence_by_expert.get(0, []) +
        confidence_by_expert.get(1, [])
    )

    if len(q8_conf) > 0 and len(others_conf) > 0:
        t_stat, p_value = stats.ttest_ind(q8_conf, others_conf)
        return t_stat, p_value
    else:
        return None, None


def create_figure(confidence_by_expert, summaries, t_stat, p_value, output_path):
    """Create box plot figure for rebuttal."""

    # Prepare data for box plot
    expert_names = ['BitNet', 'Q4', 'Q8']
    expert_quant = ['1-bit', '4-bit', '8-bit']
    expert_ids = [0, 1, 2]

    # Collect confidence values and sample counts for each expert
    plot_data = []
    means_from_summaries = []
    sample_counts = []
    total_samples = sum(summaries[str(i)]['count'] for i in expert_ids if str(i) in summaries)

    for expert_id in expert_ids:
        if expert_id in confidence_by_expert:
            plot_data.append(confidence_by_expert[expert_id])
        else:
            plot_data.append([])

        # Get mean and count from summaries (based on full dataset)
        if str(expert_id) in summaries:
            means_from_summaries.append(summaries[str(expert_id)]['avg_conf'])
            sample_counts.append(summaries[str(expert_id)]['count'])
        else:
            means_from_summaries.append(None)
            sample_counts.append(0)

    # Create figure with better proportions
    fig, ax = plt.subplots(figsize=(10, 6))

    # Create box plot with cleaner style
    bp = ax.boxplot(plot_data, patch_artist=True,
                    boxprops=dict(facecolor='lightblue', alpha=0.6, edgecolor='black', linewidth=1.5),
                    medianprops=dict(color='blue', linewidth=2.5),
                    whiskerprops=dict(color='black', linewidth=1.5),
                    capprops=dict(color='black', linewidth=1.5),
                    widths=0.5)

    # Add mean markers (red diamonds)
    for i, mean_val in enumerate(means_from_summaries):
        if mean_val is not None:
            ax.plot(i + 1, mean_val, marker='D', color='red', markersize=10, zorder=5)

    # Add dashed lines for means from full dataset (different colors per expert)
    colors = ['blue', 'orange', 'green']
    for i, (mean_val, color) in enumerate(zip(means_from_summaries, colors)):
        if mean_val is not None:
            ax.hlines(mean_val, i + 0.6, i + 1.4, colors=color,
                     linestyles='dashed', linewidth=2.5, zorder=4)

    # Add text box annotation (upper right) - corrected to 20%
    textstr = 'Q8 confidence 20% lower\n(p<0.001, t-test)'
    props = dict(boxstyle='round', facecolor='yellow', alpha=0.7, edgecolor='black', linewidth=1.5)
    ax.text(0.98, 0.97, textstr, transform=ax.transAxes, fontsize=13,
            verticalalignment='top', horizontalalignment='right', bbox=props, fontweight='bold')

    # Set x-axis labels with expert name, quantization, and percentage
    x_labels = []
    for name, quant, count in zip(expert_names, expert_quant, sample_counts):
        if total_samples > 0:
            pct = (count / total_samples) * 100
            x_labels.append(f'{name}\n({quant})\n{pct:.0f}%')
        else:
            x_labels.append(f'{name}\n({quant})')

    ax.set_xticklabels(x_labels, fontsize=12, fontweight='bold')

    # Labels (NO TITLE - moved to caption to save space)
    ax.set_ylabel('Prediction Confidence', fontsize=14, fontweight='bold')
    ax.set_xlabel('Expert (Quantization Level, % Samples)', fontsize=14, fontweight='bold')

    # Add grid (light dashed lines)
    ax.yaxis.grid(True, alpha=0.3, linestyle='--', color='gray')
    ax.set_axisbelow(True)

    # Set y-axis limits
    ax.set_ylim([0.3, 1.0])

    # Tight layout
    plt.tight_layout()

    # Save figure
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f'âœ… Figure saved to: {output_path}')

    plt.close()


def main():
    parser = argparse.ArgumentParser(
        description='Generate rebuttal confidence distribution figure'
    )
    parser.add_argument('--routing-json', required=True,
                       help='Path to routing_results.json')
    parser.add_argument('--output', required=True,
                       help='Output PDF path')

    args = parser.parse_args()

    # Load data
    print(f'Loading routing data from: {args.routing_json}')
    data = load_routing_data(args.routing_json)

    # Extract confidence by expert
    confidence_by_expert, summaries = extract_confidence_by_expert(data)

    # Print statistics
    print('\n=== Confidence Statistics ===')
    for expert_id, name in enumerate(['BitNet', 'Q4', 'Q8']):
        if str(expert_id) in summaries:
            summary = summaries[str(expert_id)]
            print(f'{name}: n={summary["count"]}, mean={summary["avg_conf"]:.3f}')

    # Compute statistical test
    t_stat, p_value = compute_statistical_test(confidence_by_expert)

    if t_stat is not None:
        print(f'\n=== Statistical Test ===')
        print(f'Q8 vs BitNet/Q4: t={t_stat:.3f}, p={p_value:.6f}')
        print(f'Significant at p<0.001: {p_value < 0.001}')

    # Create figure
    create_figure(confidence_by_expert, summaries, t_stat, p_value, args.output)


if __name__ == '__main__':
    main()
