{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0340b2b5-04a4-4a7f-b5ad-19ff4a30207f",
   "metadata": {},
   "source": [
    "# Vector Embedding Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45072bae-5600-4f7c-84e4-1fc4e5a197c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "`data_path` is assumed to have the splitted data named as \"train/\", \"val/\" and \"test/\"\n",
    "\n",
    "**SUPORTED MODELs**\n",
    "\n",
    "\n",
    "- resnet50: 1536 h.u\n",
    "- mobilenet_v3_large\n",
    "- mobilenetv4_r448_trained\n",
    "- mobilenetv4_r448\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5878001-9b8c-4d3d-a936-4d06235a34de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "model_name = \"efficientnet_b3\"#\"resnet50\"\n",
    "batch_sizes = [64]\n",
    "embedding_sizes = [1536]#[2,4,8,64,1536]\n",
    "data_path = '/Users/sebasmos/Documents/VE_paper/data/ESC-50-master/Mels_HD'\n",
    "# data_path = '/home/sebastian/codes/SensoryCity/0_classifier/Split'\n",
    "# data_path = '../data/UrbanSound8K/Mels'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39cb0a90-c2ad-4a89-baf3-3119236aab9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "MODEL_CONSTRUCTORS = {\n",
    "    'eva02_large_patch14_448_embeddings_imageNet':timm.create_model('eva02_large_patch14_448.mim_m38m_ft_in22k_in1k', pretrained=True, num_classes=0),\n",
    "    'mobilenetv4_r448_trained': timm.create_model('mobilenetv4_conv_aa_large.e230_r448_in12k_ft_in1k', pretrained=False, num_classes=0),\n",
    "    'mobilenetv4_r448': timm.create_model('mobilenetv4_conv_aa_large.e230_r448_in12k_ft_in1k', pretrained=True, num_classes=0),\n",
    "    'resnet50':models.resnet50,\n",
    "    'alexnet': models.alexnet,\n",
    "    'convnext_base': models.convnext_base,\n",
    "    'convnext_large': models.convnext_large,\n",
    "    'convnext_small': models.convnext_small,\n",
    "    'convnext_tiny': models.convnext_tiny,\n",
    "    'densenet121': models.densenet121,\n",
    "    'densenet161': models.densenet161,\n",
    "    'densenet169': models.densenet169,\n",
    "    'densenet201': models.densenet201,\n",
    "    'efficientnet_b0': models.efficientnet_b0,\n",
    "    'efficientnet_b1': models.efficientnet_b1,\n",
    "    'efficientnet_b2': models.efficientnet_b2,\n",
    "    'efficientnet_b3': models.efficientnet_b3,\n",
    "    'efficientnet_b4': models.efficientnet_b4,\n",
    "    'efficientnet_b5': models.efficientnet_b5,\n",
    "    'efficientnet_b6': models.efficientnet_b6,\n",
    "    'efficientnet_b7': models.efficientnet_b7,\n",
    "    'efficientnet_v2_l': models.efficientnet_v2_l,\n",
    "    'efficientnet_v2_m': models.efficientnet_v2_m,\n",
    "    'efficientnet_v2_s': models.efficientnet_v2_s,\n",
    "    'googlenet': models.googlenet,\n",
    "    'inception_v3': models.inception_v3,\n",
    "    'maxvit_t': models.maxvit_t,\n",
    "    'mnasnet0_5': models.mnasnet0_5,\n",
    "    'mnasnet0_75': models.mnasnet0_75,\n",
    "    'mnasnet1_0': models.mnasnet1_0,\n",
    "    'mnasnet1_3': models.mnasnet1_3,\n",
    "    'mobilenet_v2': models.mobilenet_v2,\n",
    "    'mobilenet_v3_large': models.mobilenet_v3_large,\n",
    "    'mobilenet_v3_small': models.mobilenet_v3_small,\n",
    "    'regnet_x_16gf': models.regnet_x_16gf,\n",
    "    'regnet_x_1_6gf': models.regnet_x_1_6gf,\n",
    "    'regnet_x_32gf': models.regnet_x_32gf,\n",
    "    'regnet_x_3_2gf': models.regnet_x_3_2gf,\n",
    "    'regnet_x_400mf': models.regnet_x_400mf,\n",
    "    'regnet_x_800mf': models.regnet_x_800mf,\n",
    "    'regnet_x_8gf': models.regnet_x_8gf,\n",
    "    'regnet_y_128gf': models.regnet_y_128gf,# check this regnet_y_128gf: no weigthts avaialble\n",
    "    'regnet_y_16gf': models.regnet_y_16gf,\n",
    "    'regnet_y_1_6gf': models.regnet_y_1_6gf,\n",
    "    'regnet_y_32gf': models.regnet_y_32gf,\n",
    "    'regnet_y_3_2gf': models.regnet_y_3_2gf,\n",
    "    'regnet_y_400mf': models.regnet_y_400mf,\n",
    "    'regnet_y_800mf': models.regnet_y_800mf,\n",
    "    'regnet_y_8gf': models.regnet_y_8gf,\n",
    "    'resnet101': models.resnet101,\n",
    "    'resnet152': models.resnet152,\n",
    "    'resnet18': models.resnet18,\n",
    "    'resnet34': models.resnet34,\n",
    "    'resnet50': models.resnet50,\n",
    "    'resnext101_32x8d': models.resnext101_32x8d,\n",
    "    'resnext101_64x4d': models.resnext101_64x4d,\n",
    "    'resnext50_32x4d': models.resnext50_32x4d,\n",
    "    'shufflenet_v2_x0_5': models.shufflenet_v2_x0_5,\n",
    "    'shufflenet_v2_x1_0': models.shufflenet_v2_x1_0,\n",
    "    'shufflenet_v2_x1_5': models.shufflenet_v2_x1_5,\n",
    "    'shufflenet_v2_x2_0': models.shufflenet_v2_x2_0,\n",
    "    'squeezenet1_0': models.squeezenet1_0,\n",
    "    'squeezenet1_1': models.squeezenet1_1,\n",
    "    'swin_b': models.swin_b,\n",
    "    'swin_s': models.swin_s,\n",
    "    'swin_t': models.swin_t,\n",
    "    'swin_v2_b': models.swin_v2_b,\n",
    "    'swin_v2_s': models.swin_v2_s,\n",
    "    'swin_v2_t': models.swin_v2_t,\n",
    "    'vgg11': models.vgg11,\n",
    "    'vgg11_bn': models.vgg11_bn,\n",
    "    'vgg13': models.vgg13,\n",
    "    'vgg13_bn': models.vgg13_bn,\n",
    "    'vgg16': models.vgg16,\n",
    "    'vgg16_bn': models.vgg16_bn,\n",
    "    'vgg19': models.vgg19,\n",
    "    'vgg19_bn': models.vgg19_bn,\n",
    "    'vit_b_16': models.vit_b_16,\n",
    "    'vit_b_32': models.vit_b_32,\n",
    "    'vit_h_14': models.vit_h_14,# and this..no weigthts avaialble\n",
    "    'vit_l_16': models.vit_l_16,\n",
    "    'vit_l_32': models.vit_l_32,\n",
    "    'wide_resnet101_2': models.wide_resnet101_2,\n",
    "    'wide_resnet50_2': models.wide_resnet50_2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1c58f-d275-4b39-82cb-9ec06349b322",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "370eb3e4-97f2-401c-83ba-b849b83761c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:27.029835] [11:22:27.029823] [11:22:27.029931] numpy version: 1.26.4\n",
      "CUDA version: None - Torch versteion: 2.4.0 - device count: 0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# sys.path.insert(0,'../') \n",
    "# sys.path.insert(0,'../../') \n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd \n",
    "# from MAE code\n",
    "from util.datasets import build_dataset\n",
    "import argparse\n",
    "import util.misc as misc\n",
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import timm\n",
    "\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "\n",
    "import util.lr_decay as lrd\n",
    "import util.misc as misc\n",
    "from util.datasets import build_dataset\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "\n",
    "# import models_vit\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch; print(f'numpy version: {np.__version__}\\nCUDA version: {torch.version.cuda} - Torch versteion: {torch.__version__} - device count: {torch.cuda.device_count()}')\n",
    "\n",
    "from timm.data import Mixup\n",
    "from timm.utils import accuracy\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, fbeta_score\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from qnet import *\n",
    "mp.set_sharing_strategy('file_system')\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def create_args(batch_size, model_name, embedding_size, output_dir, data_path, device):\n",
    "    parser = argparse.ArgumentParser('VE extraction', add_help=False)\n",
    "    parser.add_argument('--batch_size', default=batch_size, help='Batch size per GPU')\n",
    "    parser.add_argument('--embedding_size', default=embedding_size, help='embedding_size')\n",
    "    parser.add_argument('--epochs', default=50, type=int)\n",
    "    parser.add_argument('--accum_iter', default=4, type=int,\n",
    "                        help='Accumulate gradient iterations')\n",
    "    parser.add_argument('--model', default=model_name, type=str, metavar='MODEL',\n",
    "                        help='Name of model to train')\n",
    "    parser.add_argument('--input_size', default=224, type=int,\n",
    "                        help='images input size')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.05,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--lr', type=float, default=None, metavar='LR',\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--data_path', default=data_path, type=str,\n",
    "                        help='dataset path')\n",
    "    parser.add_argument('--nb_classes', default=5, type=int,\n",
    "                        help='number of the classification types')\n",
    "    parser.add_argument('--output_dir', default=output_dir,\n",
    "                        help='path where to save')\n",
    "    parser.add_argument('--log_dir', default='./output_dir',\n",
    "                        help='path where to tensorboard log')\n",
    "    parser.add_argument('--device', default=device,\n",
    "                        help='device to use for training/testing')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--pin_mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "        # Augmentation parameters\n",
    "    parser.add_argument('--color_jitter', type=float, default=None, metavar='PCT',\n",
    "                            help='Color jitter factor (enabled only when not using Auto/RandAug)')\n",
    "    parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                            help='Use AutoAugment policy. \"v0\" or \"original\". \" + \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "    parser.add_argument('--smoothing', type=float, default=0.1,\n",
    "                            help='Label smoothing (default: 0.1)')\n",
    "        # * Random Erase params\n",
    "    parser.add_argument('--reprob', type=float, default=0.25, metavar='PCT',\n",
    "                            help='Random erase prob (default: 0.25)')\n",
    "    parser.add_argument('--remode', type=str, default='pixel',\n",
    "                            help='Random erase mode (default: \"pixel\")')\n",
    "    parser.add_argument('--recount', type=int, default=1,\n",
    "                            help='Random erase count (default: 1)')\n",
    "    parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                            help='Do not random erase first (clean) augmentation split')\n",
    "        # * Mixup params\n",
    "    parser.add_argument('--mixup', type=float, default=0.8,\n",
    "                            help='mixup alpha, mixup enabled if > 0.')\n",
    "    parser.add_argument('--cutmix', type=float, default=1.0,\n",
    "                            help='cutmix alpha, cutmix enabled if > 0.')\n",
    "    parser.add_argument('--cutmix_minmax', type=float, nargs='+', default=None,\n",
    "                            help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "    parser.add_argument('--mixup_prob', type=float, default=1.0,\n",
    "                            help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "    parser.add_argument('--mixup_switch_prob', type=float, default=0.5,\n",
    "                            help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "\n",
    "    parser.add_argument('--mixup_mode', type=str, default='batch',\n",
    "                            help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "    parser.add_argument('--resume', default=\".\",\n",
    "                        help='resume from checkpoint')\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--eval', default=True, action='store_true',\n",
    "                        help='Perform evaluation only')\n",
    "    parser.add_argument('--dist_eval', action='store_true', default=False,\n",
    "                        help='Enabling distributed evaluation')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--dist_on_itp', action='store_true')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585d9a1-7586-414a-ad85-8ebac0172f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Image Vector Embeddings Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc75ff2-059d-475a-8edf-520c12cb9d39",
   "metadata": {},
   "source": [
    "### Extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "544be8e9-739a-4563-9aa4-7e5385f982af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:27.054006] [11:22:27.053996] [11:22:27.054062] -----------------\n",
      "efficientnet_b3_1536_bs64-----------------\n",
      "[11:22:27.054095] [11:22:27.054093] [11:22:27.054102] PARAMETERS\n",
      "Namespace(batch_size=64,\n",
      "embedding_size=1536,\n",
      "epochs=50,\n",
      "accum_iter=4,\n",
      "model='efficientnet_b3',\n",
      "input_size=224,\n",
      "weight_decay=0.05,\n",
      "lr=None,\n",
      "data_path='/Users/sebasmos/Documents/VE_paper/data/ESC-50-master/Mels_HD',\n",
      "nb_classes=5,\n",
      "output_dir='efficientnet_b3',\n",
      "log_dir='./output_dir',\n",
      "device='cpu',\n",
      "seed=0,\n",
      "pin_mem=False,\n",
      "color_jitter=None,\n",
      "aa='rand-m9-mstd0.5-inc1',\n",
      "smoothing=0.1,\n",
      "reprob=0.25,\n",
      "remode='pixel',\n",
      "recount=1,\n",
      "resplit=False,\n",
      "mixup=0.8,\n",
      "cutmix=1.0,\n",
      "cutmix_minmax=None,\n",
      "mixup_prob=1.0,\n",
      "mixup_switch_prob=0.5,\n",
      "mixup_mode='batch',\n",
      "resume='.',\n",
      "start_epoch=0,\n",
      "eval=True,\n",
      "dist_eval=False,\n",
      "num_workers=10,\n",
      "dist_on_itp=False)\n",
      "[11:22:27.397170] [11:22:27.397157] [11:22:27.397260] None None\n",
      "[11:22:27.455844] [11:22:27.455840] [11:22:27.455854] Train dataset built with 1800 images from /Users/sebasmos/Documents/VE_paper/data/ESC-50-master/Mels_HD/train.\n",
      "[11:22:27.459259] [11:22:27.459249] [11:22:27.459272] Val dataset built with 200 images from /Users/sebasmos/Documents/VE_paper/data/ESC-50-master/Mels_HD/val.\n",
      "[11:22:27.459305] [11:22:27.459302] [11:22:27.459311] Not using distributed mode\n",
      "[11:22:27.504492] [11:22:27.504490] [11:22:27.504509] [11:22:27.504485] [11:22:27.504516] [11:22:27.504515] [11:22:27.504522] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x38d7578b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [03:23<00:00,  7.26s/it]\n",
      "100%|██████████| 4/4 [00:47<00:00, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:39.671676] [11:26:39.671663] [11:26:39.671769] [11:26:39.671641] [11:26:39.671795] [11:26:39.671786] [11:26:39.671801] Completed embeddings extraction for embedding_size=1536 and batch_size=64\n",
      "[11:26:39.672166] [11:26:39.672164] [11:26:39.672174] [11:26:39.672161] [11:26:39.672181] [11:26:39.672179] [11:26:39.672186] All configurations processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for embedding_size in embedding_sizes:\n",
    "    for batch_size in batch_sizes:\n",
    "        # Create a unique output directory for each configuration\n",
    "        experiment_name = f\"{model_name}/{model_name}_{embedding_size}_bs{batch_size}\"\n",
    "        os.makedirs(experiment_name, exist_ok=True)\n",
    "\n",
    "        # Generate command-line arguments for this combination\n",
    "        args = create_args(batch_size, model_name, embedding_size, model_name, data_path, device)\n",
    "        \n",
    "        print(f\"\\n{model_name}_{embedding_size}_bs{batch_size}\".center(60,\"-\"))\n",
    "        \n",
    "        print(\"PARAMETERS\\n{}\".format(args).replace(', ', ',\\n'))\n",
    "\n",
    "        model, preprocess, transforms, data_config = initialize_model(args.model, args.embedding_size, MODEL_CONSTRUCTORS)\n",
    "        print(data_config, transforms)\n",
    "        dataset_train = build_dataset(split_type=\"train\", args=args)\n",
    "        dataset_val = build_dataset(split_type=\"val\", args=args)\n",
    "        \n",
    "        os.makedirs(model_name, exist_ok=True)\n",
    "        device = torch.device(args.device)\n",
    "\n",
    "        # set seeds\n",
    "        misc.init_distributed_mode(args)\n",
    "        seed = args.seed + misc.get_rank()\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "        if True:  # args.distributed:\n",
    "                num_tasks = misc.get_world_size()\n",
    "                global_rank = misc.get_rank()\n",
    "                sampler_train = torch.utils.data.DistributedSampler(\n",
    "                    dataset_train, num_replicas=num_tasks, rank=global_rank, shuffle=True\n",
    "                )\n",
    "                print(\"Sampler_train = %s\" % str(sampler_train))\n",
    "                if args.dist_eval:\n",
    "                    if len(dataset_val) % num_tasks != 0:\n",
    "                        print('Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. '\n",
    "                              'This will slightly alter validation results as extra duplicate entries are added to achieve '\n",
    "                              'equal num of samples per-process.')\n",
    "                    sampler_val = torch.utils.data.DistributedSampler(\n",
    "                        dataset_val, num_replicas=num_tasks, rank=global_rank, shuffle=True)  # shuffle=True to reduce monitor bias\n",
    "                else:\n",
    "                    sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "        else:\n",
    "                sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "                sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "        if global_rank == 0 and args.log_dir is not None and not args.eval:\n",
    "                os.makedirs(args.log_dir, exist_ok=True)\n",
    "                log_writer = SummaryWriter(log_dir=args.log_dir)\n",
    "        else:\n",
    "                log_writer = None\n",
    "\n",
    "        data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, sampler=sampler_train,\n",
    "                batch_size=args.batch_size,\n",
    "                num_workers=args.num_workers,\n",
    "                pin_memory=args.pin_mem,\n",
    "                drop_last=True,\n",
    "        )\n",
    "\n",
    "        data_loader_val = torch.utils.data.DataLoader(\n",
    "                dataset_val, sampler=sampler_val,\n",
    "                batch_size=args.batch_size,\n",
    "                num_workers=args.num_workers,\n",
    "                pin_memory=args.pin_mem,\n",
    "                drop_last=False\n",
    "        )\n",
    "        # Extract embeddings for training data\n",
    "        extract_embeddings(model, data_loader_train, f'{experiment_name}/train_embeddings.csv', device, preprocess=preprocess, transforms=transforms, data_config=data_config)\n",
    "\n",
    "        # Extract embeddings for validation data\n",
    "        extract_embeddings(model, data_loader_val, f'{experiment_name}/val_embeddings.csv', device, preprocess=preprocess,transforms=transforms, data_config=data_config)\n",
    "\n",
    "        print(f\"Completed embeddings extraction for embedding_size={embedding_size} and batch_size={batch_size}\")\n",
    "\n",
    "print(\"All configurations processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f01637ca-5203-422b-999b-0a112313cd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AN', 'EU', 'HS', 'ID', 'NS']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2198a06b-ab70-4503-8c5b-8e7c2fc24f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:39.685244] [11:26:39.685242] [11:26:39.685312] [11:26:39.685236] [11:26:39.685320] [11:26:39.685318] [11:26:39.685325] Label 0: AN\n",
      "[11:26:39.685334] [11:26:39.685333] [11:26:39.685339] [11:26:39.685331] [11:26:39.685346] [11:26:39.685345] [11:26:39.685352] Label 1: EU\n",
      "[11:26:39.685360] [11:26:39.685359] [11:26:39.685365] [11:26:39.685358] [11:26:39.685372] [11:26:39.685371] [11:26:39.685377] Label 2: HS\n",
      "[11:26:39.685385] [11:26:39.685384] [11:26:39.685390] [11:26:39.685382] [11:26:39.685397] [11:26:39.685395] [11:26:39.685402] Label 3: ID\n",
      "[11:26:39.685410] [11:26:39.685408] [11:26:39.685415] [11:26:39.685407] [11:26:39.685421] [11:26:39.685420] [11:26:39.685427] Label 4: NS\n"
     ]
    }
   ],
   "source": [
    "for idx, class_name in enumerate(dataset_train.classes):\n",
    "        print(f\"Label {idx}: {class_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
