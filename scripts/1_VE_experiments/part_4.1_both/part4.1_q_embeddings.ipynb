{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 0\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  310.78125\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_0/training_results.json\n",
      "SEED 1\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  444.9375\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_1/training_results.json\n",
      "SEED 2\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  514.296875\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_2/training_results.json\n",
      "SEED 3\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  467.46875\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_3/training_results.json\n",
      "SEED 4\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  520.484375\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_4/training_results.json\n",
      "SEED 5\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  491.890625\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_5/training_results.json\n",
      "SEED 6\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  541.4375\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_6/training_results.json\n",
      "SEED 7\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  170.53125\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_7/training_results.json\n",
      "SEED 8\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  168.390625\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_8/training_results.json\n",
      "SEED 9\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  231.90625\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_9/training_results.json\n",
      "SEED 10\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  250.109375\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_10/training_results.json\n",
      "SEED 11\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  226.0\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_11/training_results.json\n",
      "SEED 12\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  320.171875\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_12/training_results.json\n",
      "SEED 13\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  255.640625\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_13/training_results.json\n",
      "SEED 14\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  336.890625\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_14/training_results.json\n",
      "SEED 15\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  363.515625\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_15/training_results.json\n",
      "SEED 16\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  389.1875\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_16/training_results.json\n",
      "SEED 17\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  366.796875\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_17/training_results.json\n",
      "SEED 18\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  264.125\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_18/training_results.json\n",
      "SEED 19\n",
      "--------------------------------\n",
      "------------------part_3.1_quantized_data-------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1\n",
      "---------------------Embeddings shapes----------------------\n",
      "num columns:  302\n",
      "Starting epoch 1/300\n",
      "Epoch 1/300, F1 Score: 0.7841017185481672\n",
      "Starting epoch 2/300\n",
      "Epoch 2/300, F1 Score: 0.8223601780281712\n",
      "Starting epoch 3/300\n",
      "Epoch 3/300, F1 Score: 0.8333350708038121\n",
      "Starting epoch 4/300\n",
      "Epoch 4/300, F1 Score: 0.8401759576343631\n",
      "Starting epoch 5/300\n",
      "Epoch 5/300, F1 Score: 0.8377180488524205\n",
      "Starting epoch 6/300\n",
      "Epoch 6/300, F1 Score: 0.8430295066747582\n",
      "Starting epoch 7/300\n",
      "Epoch 7/300, F1 Score: 0.8546978891099614\n",
      "Starting epoch 8/300\n",
      "Epoch 8/300, F1 Score: 0.8552283272518866\n",
      "Starting epoch 9/300\n",
      "Epoch 9/300, F1 Score: 0.8534971461962205\n",
      "Starting epoch 10/300\n",
      "Epoch 10/300, F1 Score: 0.8494423383386075\n",
      "Starting epoch 11/300\n",
      "Epoch 11/300, F1 Score: 0.8668368493584878\n",
      "Starting epoch 12/300\n",
      "Epoch 12/300, F1 Score: 0.8621537264912946\n",
      "Starting epoch 13/300\n",
      "Epoch 13/300, F1 Score: 0.8674076524394496\n",
      "Starting epoch 14/300\n",
      "Epoch 14/300, F1 Score: 0.8540706046008363\n",
      "Starting epoch 15/300\n",
      "Epoch 15/300, F1 Score: 0.8673129862704053\n",
      "Starting epoch 16/300\n",
      "Epoch 16/300, F1 Score: 0.8641556108865295\n",
      "Starting epoch 17/300\n",
      "Epoch 17/300, F1 Score: 0.8649614690428061\n",
      "Starting epoch 18/300\n",
      "Epoch 18/300, F1 Score: 0.8730316261820665\n",
      "Starting epoch 19/300\n",
      "Epoch 19/300, F1 Score: 0.868666254954801\n",
      "Starting epoch 20/300\n",
      "Epoch 20/300, F1 Score: 0.8657490631613031\n",
      "Starting epoch 21/300\n",
      "Epoch 21/300, F1 Score: 0.8716169750842359\n",
      "Starting epoch 22/300\n",
      "Epoch 22/300, F1 Score: 0.8630100326645674\n",
      "Starting epoch 23/300\n",
      "Epoch 23/300, F1 Score: 0.8748881643255676\n",
      "Starting epoch 24/300\n",
      "Epoch 24/300, F1 Score: 0.8686261251822377\n",
      "Starting epoch 25/300\n",
      "Epoch 25/300, F1 Score: 0.8674111701874792\n",
      "Starting epoch 26/300\n",
      "Epoch 26/300, F1 Score: 0.876853556083162\n",
      "Starting epoch 27/300\n",
      "Epoch 27/300, F1 Score: 0.8665110514570254\n",
      "Starting epoch 28/300\n",
      "Epoch 28/300, F1 Score: 0.8723091320676913\n",
      "Starting epoch 29/300\n",
      "Epoch 29/300, F1 Score: 0.8822527895504898\n",
      "Starting epoch 30/300\n",
      "Epoch 30/300, F1 Score: 0.8779248043101703\n",
      "Starting epoch 31/300\n",
      "Epoch 31/300, F1 Score: 0.8832547357262137\n",
      "Starting epoch 32/300\n",
      "Epoch 32/300, F1 Score: 0.8791771920599599\n",
      "Starting epoch 33/300\n",
      "Epoch 33/300, F1 Score: 0.8712421372237436\n",
      "Starting epoch 34/300\n",
      "Epoch 34/300, F1 Score: 0.8764980578409455\n",
      "Starting epoch 35/300\n",
      "Epoch 35/300, F1 Score: 0.8889626131612677\n",
      "Starting epoch 36/300\n",
      "Epoch 36/300, F1 Score: 0.8847514558941283\n",
      "Starting epoch 37/300\n",
      "Epoch 37/300, F1 Score: 0.8829230703047747\n",
      "Starting epoch 38/300\n",
      "Epoch 38/300, F1 Score: 0.885795989336127\n",
      "Starting epoch 39/300\n",
      "Epoch 39/300, F1 Score: 0.8773579295473976\n",
      "Starting epoch 40/300\n",
      "Epoch 40/300, F1 Score: 0.8723844669101438\n",
      "Starting epoch 41/300\n",
      "Epoch 41/300, F1 Score: 0.8804382416051574\n",
      "Starting epoch 42/300\n",
      "Epoch 42/300, F1 Score: 0.8732413278486169\n",
      "Starting epoch 43/300\n",
      "Epoch 43/300, F1 Score: 0.877303313253429\n",
      "Starting epoch 44/300\n",
      "Epoch 44/300, F1 Score: 0.8835189098134897\n",
      "Starting epoch 45/300\n",
      "Epoch 45/300, F1 Score: 0.8924194441701537\n",
      "Starting epoch 46/300\n",
      "Epoch 46/300, F1 Score: 0.8821461300554162\n",
      "Starting epoch 47/300\n",
      "Epoch 47/300, F1 Score: 0.8874062200354204\n",
      "Starting epoch 48/300\n",
      "Epoch 48/300, F1 Score: 0.8943916527772557\n",
      "Starting epoch 49/300\n",
      "Epoch 49/300, F1 Score: 0.8944748564682024\n",
      "Starting epoch 50/300\n",
      "Epoch 50/300, F1 Score: 0.8856086228030956\n",
      "Starting epoch 51/300\n",
      "Epoch 51/300, F1 Score: 0.8898731427361074\n",
      "Starting epoch 52/300\n",
      "Epoch 52/300, F1 Score: 0.8822272660152165\n",
      "Starting epoch 53/300\n",
      "Epoch 53/300, F1 Score: 0.8909075995236243\n",
      "Starting epoch 54/300\n",
      "Epoch 54/300, F1 Score: 0.8795593112596074\n",
      "Starting epoch 55/300\n",
      "Epoch 55/300, F1 Score: 0.8857580672829317\n",
      "Starting epoch 56/300\n",
      "Epoch 56/300, F1 Score: 0.8766704879210095\n",
      "Starting epoch 57/300\n",
      "Epoch 57/300, F1 Score: 0.8747942438917247\n",
      "Starting epoch 58/300\n",
      "Epoch 58/300, F1 Score: 0.8801212781900728\n",
      "Starting epoch 59/300\n",
      "Epoch 59/300, F1 Score: 0.8811929972586557\n",
      "Starting epoch 60/300\n",
      "Epoch 60/300, F1 Score: 0.8882737334772575\n",
      "Starting epoch 61/300\n",
      "Epoch 61/300, F1 Score: 0.8906555331504835\n",
      "Starting epoch 62/300\n",
      "Epoch 62/300, F1 Score: 0.8882943067971941\n",
      "Starting epoch 63/300\n",
      "Epoch 63/300, F1 Score: 0.8872215695546479\n",
      "Starting epoch 64/300\n",
      "Epoch 64/300, F1 Score: 0.8809469317575341\n",
      "Starting epoch 65/300\n",
      "Epoch 65/300, F1 Score: 0.8825834951593045\n",
      "Starting epoch 66/300\n",
      "Epoch 66/300, F1 Score: 0.8762116653476649\n",
      "Starting epoch 67/300\n",
      "Epoch 67/300, F1 Score: 0.881106672987616\n",
      "Starting epoch 68/300\n",
      "Epoch 68/300, F1 Score: 0.884579481621076\n",
      "Starting epoch 69/300\n",
      "Epoch 69/300, F1 Score: 0.8932700412982651\n",
      "Starting epoch 70/300\n",
      "Epoch 70/300, F1 Score: 0.8873879063616157\n",
      "Starting epoch 71/300\n",
      "Epoch 71/300, F1 Score: 0.8850988787928429\n",
      "Starting epoch 72/300\n",
      "Epoch 72/300, F1 Score: 0.8908327690817475\n",
      "Starting epoch 73/300\n",
      "Epoch 73/300, F1 Score: 0.8845889226955076\n",
      "Starting epoch 74/300\n",
      "Epoch 74/300, F1 Score: 0.8872670446239658\n",
      "Starting epoch 75/300\n",
      "Epoch 75/300, F1 Score: 0.8870750612657\n",
      "Starting epoch 76/300\n",
      "Epoch 76/300, F1 Score: 0.8954875337997076\n",
      "Starting epoch 77/300\n",
      "Epoch 77/300, F1 Score: 0.899167659194558\n",
      "Starting epoch 78/300\n",
      "Epoch 78/300, F1 Score: 0.8980432137260778\n",
      "Starting epoch 79/300\n",
      "Epoch 79/300, F1 Score: 0.8955304601993912\n",
      "Starting epoch 80/300\n",
      "Epoch 80/300, F1 Score: 0.8921585155295811\n",
      "Starting epoch 81/300\n",
      "Epoch 81/300, F1 Score: 0.8967773527114353\n",
      "Starting epoch 82/300\n",
      "Epoch 82/300, F1 Score: 0.8942887073857874\n",
      "Starting epoch 83/300\n",
      "Epoch 83/300, F1 Score: 0.8965287822737692\n",
      "Starting epoch 84/300\n",
      "Epoch 84/300, F1 Score: 0.894193492693999\n",
      "Starting epoch 85/300\n",
      "Epoch 85/300, F1 Score: 0.8967487402355898\n",
      "Starting epoch 86/300\n",
      "Epoch 86/300, F1 Score: 0.8981305502850565\n",
      "Starting epoch 87/300\n",
      "Epoch 87/300, F1 Score: 0.8953811313932186\n",
      "Starting epoch 88/300\n",
      "Epoch 88/300, F1 Score: 0.8940245544207197\n",
      "Starting epoch 89/300\n",
      "Epoch 89/300, F1 Score: 0.8906443954326907\n",
      "Starting epoch 90/300\n",
      "Epoch 90/300, F1 Score: 0.8929600664261766\n",
      "Starting epoch 91/300\n",
      "Epoch 91/300, F1 Score: 0.8953305628755276\n",
      "Starting epoch 92/300\n",
      "Epoch 92/300, F1 Score: 0.8915878845566115\n",
      "Starting epoch 93/300\n",
      "Epoch 93/300, F1 Score: 0.8914876805801085\n",
      "Starting epoch 94/300\n",
      "Epoch 94/300, F1 Score: 0.8952590523802949\n",
      "Starting epoch 95/300\n",
      "Epoch 95/300, F1 Score: 0.8928382418152012\n",
      "Starting epoch 96/300\n",
      "Epoch 96/300, F1 Score: 0.8952778087853515\n",
      "Starting epoch 97/300\n",
      "Epoch 97/300, F1 Score: 0.8977284754960474\n",
      "Starting epoch 98/300\n",
      "Epoch 98/300, F1 Score: 0.9002382506640227\n",
      "Starting epoch 99/300\n",
      "Epoch 99/300, F1 Score: 0.8954309878768503\n",
      "Starting epoch 100/300\n",
      "Epoch 100/300, F1 Score: 0.8953726421039697\n",
      "Starting epoch 101/300\n",
      "Epoch 101/300, F1 Score: 0.8979161256057481\n",
      "Starting epoch 102/300\n",
      "Epoch 102/300, F1 Score: 0.8978797371656185\n",
      "Starting epoch 103/300\n",
      "Epoch 103/300, F1 Score: 0.8955623140405671\n",
      "Starting epoch 104/300\n",
      "Epoch 104/300, F1 Score: 0.8966560698172399\n",
      "Starting epoch 105/300\n",
      "Epoch 105/300, F1 Score: 0.8955416981458859\n",
      "Starting epoch 106/300\n",
      "Epoch 106/300, F1 Score: 0.8955047070956674\n",
      "Starting epoch 107/300\n",
      "Epoch 107/300, F1 Score: 0.8941948273181906\n",
      "Starting epoch 108/300\n",
      "Epoch 108/300, F1 Score: 0.8942664219919402\n",
      "Starting epoch 109/300\n",
      "Epoch 109/300, F1 Score: 0.894120182200554\n",
      "Starting epoch 110/300\n",
      "Epoch 110/300, F1 Score: 0.8930234668605893\n",
      "Starting epoch 111/300\n",
      "Epoch 111/300, F1 Score: 0.8943285172538998\n",
      "Starting epoch 112/300\n",
      "Epoch 112/300, F1 Score: 0.8954202143369897\n",
      "Starting epoch 113/300\n",
      "Epoch 113/300, F1 Score: 0.8930485739043396\n",
      "Starting epoch 114/300\n",
      "Epoch 114/300, F1 Score: 0.8930698708636486\n",
      "Starting epoch 115/300\n",
      "Epoch 115/300, F1 Score: 0.8942499862469048\n",
      "Starting epoch 116/300\n",
      "Epoch 116/300, F1 Score: 0.8954531259889452\n",
      "Starting epoch 117/300\n",
      "Epoch 117/300, F1 Score: 0.8941913674937768\n",
      "Starting epoch 118/300\n",
      "Epoch 118/300, F1 Score: 0.8942570671503388\n",
      "Starting epoch 119/300\n",
      "Epoch 119/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 120/300\n",
      "Epoch 120/300, F1 Score: 0.8954591261910907\n",
      "Starting epoch 121/300\n",
      "Epoch 121/300, F1 Score: 0.8942294993213746\n",
      "Starting epoch 122/300\n",
      "Epoch 122/300, F1 Score: 0.8941227773421383\n",
      "Starting epoch 123/300\n",
      "Epoch 123/300, F1 Score: 0.8930260269248781\n",
      "Starting epoch 124/300\n",
      "Epoch 124/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 125/300\n",
      "Epoch 125/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 126/300\n",
      "Epoch 126/300, F1 Score: 0.89542120548024\n",
      "Starting epoch 127/300\n",
      "Epoch 127/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 128/300\n",
      "Epoch 128/300, F1 Score: 0.8966557037738723\n",
      "Starting epoch 129/300\n",
      "Epoch 129/300, F1 Score: 0.8954541009703568\n",
      "Starting epoch 130/300\n",
      "Epoch 130/300, F1 Score: 0.8955201378659337\n",
      "Starting epoch 131/300\n",
      "Epoch 131/300, F1 Score: 0.8931307308854262\n",
      "Starting epoch 132/300\n",
      "Epoch 132/300, F1 Score: 0.8919271178889028\n",
      "Starting epoch 133/300\n",
      "Epoch 133/300, F1 Score: 0.8943057608018248\n",
      "Starting epoch 134/300\n",
      "Epoch 134/300, F1 Score: 0.89309760663475\n",
      "Starting epoch 135/300\n",
      "Epoch 135/300, F1 Score: 0.8931647429658243\n",
      "Starting epoch 136/300\n",
      "Epoch 136/300, F1 Score: 0.894289621574686\n",
      "Starting epoch 137/300\n",
      "Epoch 137/300, F1 Score: 0.8942686550802035\n",
      "Starting epoch 138/300\n",
      "Epoch 138/300, F1 Score: 0.8930635945543518\n",
      "Starting epoch 139/300\n",
      "Epoch 139/300, F1 Score: 0.8918560104925285\n",
      "Starting epoch 140/300\n",
      "Epoch 140/300, F1 Score: 0.8931361720201227\n",
      "Starting epoch 141/300\n",
      "Epoch 141/300, F1 Score: 0.890731446722585\n",
      "Starting epoch 142/300\n",
      "Epoch 142/300, F1 Score: 0.8919595014434438\n",
      "Starting epoch 143/300\n",
      "Epoch 143/300, F1 Score: 0.8943922359855799\n",
      "Starting epoch 144/300\n",
      "Epoch 144/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 145/300\n",
      "Epoch 145/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 146/300\n",
      "Epoch 146/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 147/300\n",
      "Epoch 147/300, F1 Score: 0.8919652873657763\n",
      "Starting epoch 148/300\n",
      "Epoch 148/300, F1 Score: 0.8919652873657763\n",
      "Early stopping triggered\n",
      "model_memory_train:  225.953125\n",
      "F1 on eval data:  0.8919652873657763\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_19/training_results.json\n"
     ]
    }
   ],
   "source": [
    "# efficientnet_b3_1536_bs64\n",
    "# !python q_data_trainer_4.1.py \\\n",
    "#     --data_path \"/Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64\" \\\n",
    "#     --num_epochs 300 \\\n",
    "#     --total_num_seed 20 \\\n",
    "#     --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results\"\n",
    "\n",
    "# efficientnet_b3_1536_bs64_PCA0.95\n",
    "!python q_data_trainer_4.1.py \\\n",
    "   --data_path \"/Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95\" \\\n",
    "    --num_epochs 300 \\\n",
    "    --total_num_seed 20 \\\n",
    "    --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 0\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "[W130 11:40:44.901992000 qlinear_dynamic.cpp:250] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
      "total_cpu_memory_inference (MB):  371.90625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.33963704109192, 'Inference time': 0.02563023567199707, 'Mem. Train (MB)': 310.78125, 'Mem. Infer (MB)': 371.90625}\n",
      "Inference time: 0.03 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.33963704109192, 'Inference time': 0.02563023567199707, 'Mem. Train (MB)': 310.78125, 'Mem. Infer (MB)': 371.90625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_0/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_0.pkl\n",
      "SEED 1\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  421.90625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 19.496602296829224, 'Inference time': 0.021561145782470703, 'Mem. Train (MB)': 444.9375, 'Mem. Infer (MB)': 421.90625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 19.496602296829224, 'Inference time': 0.021561145782470703, 'Mem. Train (MB)': 444.9375, 'Mem. Infer (MB)': 421.90625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_1/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_1.pkl\n",
      "SEED 2\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  444.234375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.68435788154602, 'Inference time': 0.020756959915161133, 'Mem. Train (MB)': 514.296875, 'Mem. Infer (MB)': 444.234375}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.68435788154602, 'Inference time': 0.020756959915161133, 'Mem. Train (MB)': 514.296875, 'Mem. Infer (MB)': 444.234375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_2/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_2.pkl\n",
      "SEED 3\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  466.625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.75921106338501, 'Inference time': 0.021544933319091797, 'Mem. Train (MB)': 467.46875, 'Mem. Infer (MB)': 466.625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.75921106338501, 'Inference time': 0.021544933319091797, 'Mem. Train (MB)': 467.46875, 'Mem. Infer (MB)': 466.625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_3/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_3.pkl\n",
      "SEED 4\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  490.484375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 22.20549774169922, 'Inference time': 0.017956018447875977, 'Mem. Train (MB)': 520.484375, 'Mem. Infer (MB)': 490.484375}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 22.20549774169922, 'Inference time': 0.017956018447875977, 'Mem. Train (MB)': 520.484375, 'Mem. Infer (MB)': 490.484375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_4/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_4.pkl\n",
      "SEED 5\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  519.578125\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.97760510444641, 'Inference time': 0.021300792694091797, 'Mem. Train (MB)': 491.890625, 'Mem. Infer (MB)': 519.578125}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.97760510444641, 'Inference time': 0.021300792694091797, 'Mem. Train (MB)': 491.890625, 'Mem. Infer (MB)': 519.578125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_5/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_5.pkl\n",
      "SEED 6\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  545.53125\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.409868955612183, 'Inference time': 0.02308511734008789, 'Mem. Train (MB)': 541.4375, 'Mem. Infer (MB)': 545.53125}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.409868955612183, 'Inference time': 0.02308511734008789, 'Mem. Train (MB)': 541.4375, 'Mem. Infer (MB)': 545.53125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_6/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_6.pkl\n",
      "SEED 7\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  556.625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 23.692877054214478, 'Inference time': 0.02645087242126465, 'Mem. Train (MB)': 170.53125, 'Mem. Infer (MB)': 556.625}\n",
      "Inference time: 0.03 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 23.692877054214478, 'Inference time': 0.02645087242126465, 'Mem. Train (MB)': 170.53125, 'Mem. Infer (MB)': 556.625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_7/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_7.pkl\n",
      "SEED 8\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  573.9375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 23.8172390460968, 'Inference time': 0.01935267448425293, 'Mem. Train (MB)': 168.390625, 'Mem. Infer (MB)': 573.9375}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 23.8172390460968, 'Inference time': 0.01935267448425293, 'Mem. Train (MB)': 168.390625, 'Mem. Infer (MB)': 573.9375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_8/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_8.pkl\n",
      "SEED 9\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  587.390625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.106123208999634, 'Inference time': 0.023756027221679688, 'Mem. Train (MB)': 231.90625, 'Mem. Infer (MB)': 587.390625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.106123208999634, 'Inference time': 0.023756027221679688, 'Mem. Train (MB)': 231.90625, 'Mem. Infer (MB)': 587.390625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_9/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_9.pkl\n",
      "SEED 10\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  604.203125\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.68031597137451, 'Inference time': 0.023402929306030273, 'Mem. Train (MB)': 250.109375, 'Mem. Infer (MB)': 604.203125}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.68031597137451, 'Inference time': 0.023402929306030273, 'Mem. Train (MB)': 250.109375, 'Mem. Infer (MB)': 604.203125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_10/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_10.pkl\n",
      "SEED 11\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  610.8125\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.77468729019165, 'Inference time': 0.02328205108642578, 'Mem. Train (MB)': 226.0, 'Mem. Infer (MB)': 610.8125}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.77468729019165, 'Inference time': 0.02328205108642578, 'Mem. Train (MB)': 226.0, 'Mem. Infer (MB)': 610.8125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_11/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_11.pkl\n",
      "SEED 12\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  612.421875\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.819145917892456, 'Inference time': 0.019723892211914062, 'Mem. Train (MB)': 320.171875, 'Mem. Infer (MB)': 612.421875}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.819145917892456, 'Inference time': 0.019723892211914062, 'Mem. Train (MB)': 320.171875, 'Mem. Infer (MB)': 612.421875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_12/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_12.pkl\n",
      "SEED 13\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  617.71875\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.512567043304443, 'Inference time': 0.01853322982788086, 'Mem. Train (MB)': 255.640625, 'Mem. Infer (MB)': 617.71875}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.512567043304443, 'Inference time': 0.01853322982788086, 'Mem. Train (MB)': 255.640625, 'Mem. Infer (MB)': 617.71875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_13/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_13.pkl\n",
      "SEED 14\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  627.265625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.732505083084106, 'Inference time': 0.022459030151367188, 'Mem. Train (MB)': 336.890625, 'Mem. Infer (MB)': 627.265625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.732505083084106, 'Inference time': 0.022459030151367188, 'Mem. Train (MB)': 336.890625, 'Mem. Infer (MB)': 627.265625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_14/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_14.pkl\n",
      "SEED 15\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  639.25\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.941837072372437, 'Inference time': 0.03355002403259277, 'Mem. Train (MB)': 363.515625, 'Mem. Infer (MB)': 639.25}\n",
      "Inference time: 0.03 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.941837072372437, 'Inference time': 0.03355002403259277, 'Mem. Train (MB)': 363.515625, 'Mem. Infer (MB)': 639.25}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_15/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_15.pkl\n",
      "SEED 16\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  655.625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.968079805374146, 'Inference time': 0.06859278678894043, 'Mem. Train (MB)': 389.1875, 'Mem. Infer (MB)': 655.625}\n",
      "Inference time: 0.07 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.968079805374146, 'Inference time': 0.06859278678894043, 'Mem. Train (MB)': 389.1875, 'Mem. Infer (MB)': 655.625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_16/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_16.pkl\n",
      "SEED 17\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  669.859375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.608007192611694, 'Inference time': 0.023406982421875, 'Mem. Train (MB)': 366.796875, 'Mem. Infer (MB)': 669.859375}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 20.608007192611694, 'Inference time': 0.023406982421875, 'Mem. Train (MB)': 366.796875, 'Mem. Infer (MB)': 669.859375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_17/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_17.pkl\n",
      "SEED 18\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  673.46875\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 22.635175228118896, 'Inference time': 0.01975226402282715, 'Mem. Train (MB)': 264.125, 'Mem. Infer (MB)': 673.46875}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 22.635175228118896, 'Inference time': 0.01975226402282715, 'Mem. Train (MB)': 264.125, 'Mem. Infer (MB)': 673.46875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_18/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_18.pkl\n",
      "SEED 19\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "num_columns:  302\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/q_data_inference4.1.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  678.96875\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.30686068534851, 'Inference time': 0.021893024444580078, 'Mem. Train (MB)': 225.953125, 'Mem. Infer (MB)': 678.96875}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8977634340619587, 'F0.75 Score': 0.8978593648765584, 'Precision': 0.8986336023368853, 'Recall': 0.8983253588516746, 'Training time': 21.30686068534851, 'Inference time': 0.021893024444580078, 'Mem. Train (MB)': 225.953125, 'Mem. Infer (MB)': 678.96875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_19/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1_19.pkl\n",
      "/Users/sebasmos/Documents/VE_paper/qnet/graphics.py:102: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(5, 4))\n",
      "Metrics for all seeds: \n",
      "   EMB_size_out  Accuracy  ...  Mem. Train (MB)  Mem. Infer (MB)\n",
      "0           302  0.898325  ...       310.781250       371.906250\n",
      "0           302  0.898325  ...       444.937500       421.906250\n",
      "0           302  0.898325  ...       514.296875       444.234375\n",
      "0           302  0.898325  ...       467.468750       466.625000\n",
      "0           302  0.898325  ...       520.484375       490.484375\n",
      "0           302  0.898325  ...       491.890625       519.578125\n",
      "0           302  0.898325  ...       541.437500       545.531250\n",
      "0           302  0.898325  ...       170.531250       556.625000\n",
      "0           302  0.898325  ...       168.390625       573.937500\n",
      "0           302  0.898325  ...       231.906250       587.390625\n",
      "0           302  0.898325  ...       250.109375       604.203125\n",
      "0           302  0.898325  ...       226.000000       610.812500\n",
      "0           302  0.898325  ...       320.171875       612.421875\n",
      "0           302  0.898325  ...       255.640625       617.718750\n",
      "0           302  0.898325  ...       336.890625       627.265625\n",
      "0           302  0.898325  ...       363.515625       639.250000\n",
      "0           302  0.898325  ...       389.187500       655.625000\n",
      "0           302  0.898325  ...       366.796875       669.859375\n",
      "0           302  0.898325  ...       264.125000       673.468750\n",
      "0           302  0.898325  ...       225.953125       678.968750\n",
      "\n",
      "[20 rows x 10 columns]\n",
      "Consolidated metrics saved at /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/consolidated_metrics_mlp.csv\n",
      "Average and standard deviation metrics saved at /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/average_metrics_mlp.csv\n",
      "   F1 Score_mean  F1 Score_std  ...  Mem. Infer (MB)_mean  Mem. Infer (MB)_std\n",
      "0       0.897763  1.139065e-16  ...            568.390625             89.57671\n",
      "\n",
      "[1 rows x 8 columns]\n",
      "Evaluation across different seeds completed. Results saved to the output directory.\n"
     ]
    }
   ],
   "source": [
    "# efficientnet_b3_1536_bs64\n",
    "# !python q_data_inference4.1.py \\\n",
    "#     --data_path \"/Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64\" \\\n",
    "#     --total_num_seed 20 \\\n",
    "#     --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results\"\n",
    "\n",
    "# efficientnet_b3_1536_bs64_PCA0.95\n",
    "!python q_data_inference4.1.py \\\n",
    "    --data_path \"/Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95\" \\\n",
    "    --total_num_seed 20 \\\n",
    "    --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_0/best_model.pth\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_4.1_both/calc_flops4.1.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "[W130 11:40:54.801277000 qlinear_dynamic.cpp:250] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  0       \n",
      "fwd MACs:                                                               0 MACs  \n",
      "fwd FLOPs:                                                              2.693 KFLOPS\n",
      "fwd+bwd MACs:                                                           0 MACs  \n",
      "fwd+bwd FLOPs:                                                          8.079 KFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "QClassifier(\n",
      "  0 = 0% Params, 0 MACs = 0% MACs, 2.69 KFLOPS = 100% FLOPs\n",
      "  (fc_layers): Sequential(\n",
      "    0 = 0% Params, 0 MACs = 0% MACs, 2.69 KFLOPS = 99.8143% FLOPs\n",
      "    (0): DynamicQuantizedLinear(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=302, out_features=256, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (1): LayerNorm(0 = 0% Params, 0 MACs = 0% MACs, 1.28 KFLOPS = 47.5306% FLOPs, (256,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 256 FLOPS = 9.5061% FLOPs)\n",
      "    (3): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
      "    (4): DynamicQuantizedLinear(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=256, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (5): LayerNorm(0 = 0% Params, 0 MACs = 0% MACs, 640 FLOPS = 23.7653% FLOPs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "    (6): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 128 FLOPS = 4.7531% FLOPs)\n",
      "    (7): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
      "    (8): DynamicQuantizedLinear(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=128, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (9): LayerNorm(0 = 0% Params, 0 MACs = 0% MACs, 320 FLOPS = 11.8827% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\n",
      "    (10): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 64 FLOPS = 2.3765% FLOPs)\n",
      "    (11): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
      "  )\n",
      "  (output_layer): DynamicQuantizedLinear(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=5, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (activation_fn): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  (softmax): Softmax(0 = 0% Params, 0 MACs = 0% MACs, 5 FLOPS = 0.1857% FLOPs, dim=1)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "{'KFLOPS': 2.693, 'KMACS': 0.0, 'KPARAMS': 0.0}\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_both4.1/seed_0/flops_results.csv\n",
      "   KFLOPS  KMACS  KPARAMS\n",
      "0   2.693    0.0      0.0\n"
     ]
    }
   ],
   "source": [
    "# efficientnet_b3_1536_bs64\n",
    "# !python calc_flops4.1.py \\\n",
    "#     --data_path \"/Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64\" \\\n",
    "#     --seed_folder 0 \\\n",
    "#     --num_classes 5 \\\n",
    "#     --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results\"\n",
    "# efficientnet_b3_1536_bs64_PCA0.95\n",
    "\n",
    "!python calc_flops4.1.py \\\n",
    "    --data_path \"/Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95\" \\\n",
    "    --seed_folder 0 \\\n",
    "    --num_classes 5 \\\n",
    "    --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARF_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
