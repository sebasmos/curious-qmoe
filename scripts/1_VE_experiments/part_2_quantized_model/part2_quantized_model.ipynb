{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0340b2b5-04a4-4a7f-b5ad-19ff4a30207f",
   "metadata": {},
   "source": [
    "# 1. Quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704348a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 0\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "[W131 04:09:16.248665000 qlinear_dynamic.cpp:250] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
      "total_cpu_memory_inference (MB):  372.703125\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8971291866028708, 'F1 Score': 0.896390040546807, 'F0.75 Score': 0.8966185589034049, 'Precision': 0.8981223464117503, 'Recall': 0.8971291866028708, 'Training time': 29.036007165908813, 'Inference time': 0.022436857223510742, 'Mem. Train (MB)': 378.96875, 'Mem. Infer (MB)': 372.703125}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8971291866028708, 'F1 Score': 0.896390040546807, 'F0.75 Score': 0.8966185589034049, 'Precision': 0.8981223464117503, 'Recall': 0.8971291866028708, 'Training time': 29.036007165908813, 'Inference time': 0.022436857223510742, 'Mem. Train (MB)': 378.96875, 'Mem. Infer (MB)': 372.703125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_0/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_0.pkl\n",
      "SEED 1\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  427.0625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8935406698564593, 'F1 Score': 0.892845603544157, 'F0.75 Score': 0.893082473896254, 'Precision': 0.8945897107821489, 'Recall': 0.8935406698564593, 'Training time': 22.135308027267456, 'Inference time': 0.0235440731048584, 'Mem. Train (MB)': 204.296875, 'Mem. Infer (MB)': 427.0625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8935406698564593, 'F1 Score': 0.892845603544157, 'F0.75 Score': 0.893082473896254, 'Precision': 0.8945897107821489, 'Recall': 0.8935406698564593, 'Training time': 22.135308027267456, 'Inference time': 0.0235440731048584, 'Mem. Train (MB)': 204.296875, 'Mem. Infer (MB)': 427.0625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_1/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_1.pkl\n",
      "SEED 2\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  451.140625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8851674641148325, 'F1 Score': 0.8846131449863581, 'F0.75 Score': 0.8846927965221855, 'Precision': 0.8853812936484238, 'Recall': 0.8851674641148325, 'Training time': 20.445406913757324, 'Inference time': 0.02276611328125, 'Mem. Train (MB)': 344.203125, 'Mem. Infer (MB)': 451.140625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8851674641148325, 'F1 Score': 0.8846131449863581, 'F0.75 Score': 0.8846927965221855, 'Precision': 0.8853812936484238, 'Recall': 0.8851674641148325, 'Training time': 20.445406913757324, 'Inference time': 0.02276611328125, 'Mem. Train (MB)': 344.203125, 'Mem. Infer (MB)': 451.140625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_2/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_2.pkl\n",
      "SEED 3\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  463.03125\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8919736856081403, 'F0.75 Score': 0.8920772392508536, 'Precision': 0.8927588070134197, 'Recall': 0.8923444976076556, 'Training time': 30.743158102035522, 'Inference time': 0.02638697624206543, 'Mem. Train (MB)': 402.015625, 'Mem. Infer (MB)': 463.03125}\n",
      "Inference time: 0.03 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8919736856081403, 'F0.75 Score': 0.8920772392508536, 'Precision': 0.8927588070134197, 'Recall': 0.8923444976076556, 'Training time': 30.743158102035522, 'Inference time': 0.02638697624206543, 'Mem. Train (MB)': 402.015625, 'Mem. Infer (MB)': 463.03125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_3/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_3.pkl\n",
      "SEED 4\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  449.890625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.895933014354067, 'F1 Score': 0.8952344054070595, 'F0.75 Score': 0.8953821105536031, 'Precision': 0.8964708692370896, 'Recall': 0.895933014354067, 'Training time': 14.509362936019897, 'Inference time': 0.01971912384033203, 'Mem. Train (MB)': 497.40625, 'Mem. Infer (MB)': 449.890625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.895933014354067, 'F1 Score': 0.8952344054070595, 'F0.75 Score': 0.8953821105536031, 'Precision': 0.8964708692370896, 'Recall': 0.895933014354067, 'Training time': 14.509362936019897, 'Inference time': 0.01971912384033203, 'Mem. Train (MB)': 497.40625, 'Mem. Infer (MB)': 449.890625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_4/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_4.pkl\n",
      "SEED 5\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  474.28125\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8851674641148325, 'F1 Score': 0.8849065484704423, 'F0.75 Score': 0.885003638578694, 'Precision': 0.8856059600851306, 'Recall': 0.8851674641148325, 'Training time': 20.491344928741455, 'Inference time': 0.01752495765686035, 'Mem. Train (MB)': 475.53125, 'Mem. Infer (MB)': 474.28125}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8851674641148325, 'F1 Score': 0.8849065484704423, 'F0.75 Score': 0.885003638578694, 'Precision': 0.8856059600851306, 'Recall': 0.8851674641148325, 'Training time': 20.491344928741455, 'Inference time': 0.01752495765686035, 'Mem. Train (MB)': 475.53125, 'Mem. Infer (MB)': 474.28125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_5/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_5.pkl\n",
      "SEED 6\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  490.65625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.881578947368421, 'F1 Score': 0.8815984223575665, 'F0.75 Score': 0.8817249702025496, 'Precision': 0.8822884982134178, 'Recall': 0.881578947368421, 'Training time': 15.296813249588013, 'Inference time': 0.022602081298828125, 'Mem. Train (MB)': 400.6875, 'Mem. Infer (MB)': 490.65625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.881578947368421, 'F1 Score': 0.8815984223575665, 'F0.75 Score': 0.8817249702025496, 'Precision': 0.8822884982134178, 'Recall': 0.881578947368421, 'Training time': 15.296813249588013, 'Inference time': 0.022602081298828125, 'Mem. Train (MB)': 400.6875, 'Mem. Infer (MB)': 490.65625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_6/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_6.pkl\n",
      "SEED 7\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  505.421875\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8839712918660287, 'F1 Score': 0.8834283826002264, 'F0.75 Score': 0.8836352112062797, 'Precision': 0.8849129012212511, 'Recall': 0.8839712918660287, 'Training time': 10.247481107711792, 'Inference time': 0.023419857025146484, 'Mem. Train (MB)': 307.140625, 'Mem. Infer (MB)': 505.421875}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8839712918660287, 'F1 Score': 0.8834283826002264, 'F0.75 Score': 0.8836352112062797, 'Precision': 0.8849129012212511, 'Recall': 0.8839712918660287, 'Training time': 10.247481107711792, 'Inference time': 0.023419857025146484, 'Mem. Train (MB)': 307.140625, 'Mem. Infer (MB)': 505.421875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_7/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_7.pkl\n",
      "SEED 8\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  506.9375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8911483253588517, 'F1 Score': 0.8910500461329023, 'F0.75 Score': 0.8911394637344386, 'Precision': 0.8916166370727597, 'Recall': 0.8911483253588517, 'Training time': 14.603645324707031, 'Inference time': 0.020483016967773438, 'Mem. Train (MB)': 242.71875, 'Mem. Infer (MB)': 506.9375}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8911483253588517, 'F1 Score': 0.8910500461329023, 'F0.75 Score': 0.8911394637344386, 'Precision': 0.8916166370727597, 'Recall': 0.8911483253588517, 'Training time': 14.603645324707031, 'Inference time': 0.020483016967773438, 'Mem. Train (MB)': 242.71875, 'Mem. Infer (MB)': 506.9375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_8/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_8.pkl\n",
      "SEED 9\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  517.828125\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8924663298949832, 'F0.75 Score': 0.8926570030954394, 'Precision': 0.8934542884727902, 'Recall': 0.8923444976076556, 'Training time': 17.402846097946167, 'Inference time': 0.02295994758605957, 'Mem. Train (MB)': 283.203125, 'Mem. Infer (MB)': 517.828125}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8924663298949832, 'F0.75 Score': 0.8926570030954394, 'Precision': 0.8934542884727902, 'Recall': 0.8923444976076556, 'Training time': 17.402846097946167, 'Inference time': 0.02295994758605957, 'Mem. Train (MB)': 283.203125, 'Mem. Infer (MB)': 517.828125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_9/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_9.pkl\n",
      "SEED 10\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  529.15625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8839712918660287, 'F1 Score': 0.8833138999983028, 'F0.75 Score': 0.8833530694962299, 'Precision': 0.8839070443316038, 'Recall': 0.8839712918660287, 'Training time': 13.581754207611084, 'Inference time': 0.022010087966918945, 'Mem. Train (MB)': 300.9375, 'Mem. Infer (MB)': 529.15625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8839712918660287, 'F1 Score': 0.8833138999983028, 'F0.75 Score': 0.8833530694962299, 'Precision': 0.8839070443316038, 'Recall': 0.8839712918660287, 'Training time': 13.581754207611084, 'Inference time': 0.022010087966918945, 'Mem. Train (MB)': 300.9375, 'Mem. Infer (MB)': 529.15625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_10/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_10.pkl\n",
      "SEED 11\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  542.375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8947368421052632, 'F1 Score': 0.8938215457231823, 'F0.75 Score': 0.8942056605590868, 'Precision': 0.896645805830056, 'Recall': 0.8947368421052632, 'Training time': 17.422100067138672, 'Inference time': 0.02040886878967285, 'Mem. Train (MB)': 309.546875, 'Mem. Infer (MB)': 542.375}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8947368421052632, 'F1 Score': 0.8938215457231823, 'F0.75 Score': 0.8942056605590868, 'Precision': 0.896645805830056, 'Recall': 0.8947368421052632, 'Training time': 17.422100067138672, 'Inference time': 0.02040886878967285, 'Mem. Train (MB)': 309.546875, 'Mem. Infer (MB)': 542.375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_11/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_11.pkl\n",
      "SEED 12\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  547.8125\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8899521531100478, 'F1 Score': 0.889145414820899, 'F0.75 Score': 0.8893230100102166, 'Precision': 0.8906322866889844, 'Recall': 0.8899521531100478, 'Training time': 19.121757984161377, 'Inference time': 0.01978325843811035, 'Mem. Train (MB)': 398.84375, 'Mem. Infer (MB)': 547.8125}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8899521531100478, 'F1 Score': 0.889145414820899, 'F0.75 Score': 0.8893230100102166, 'Precision': 0.8906322866889844, 'Recall': 0.8899521531100478, 'Training time': 19.121757984161377, 'Inference time': 0.01978325843811035, 'Mem. Train (MB)': 398.84375, 'Mem. Infer (MB)': 547.8125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_12/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_12.pkl\n",
      "SEED 13\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  557.84375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8947368421052632, 'F1 Score': 0.8942129064096691, 'F0.75 Score': 0.8943276660512579, 'Precision': 0.8951642924647828, 'Recall': 0.8947368421052632, 'Training time': 23.60836100578308, 'Inference time': 0.02038407325744629, 'Mem. Train (MB)': 281.5, 'Mem. Infer (MB)': 557.84375}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8947368421052632, 'F1 Score': 0.8942129064096691, 'F0.75 Score': 0.8943276660512579, 'Precision': 0.8951642924647828, 'Recall': 0.8947368421052632, 'Training time': 23.60836100578308, 'Inference time': 0.02038407325744629, 'Mem. Train (MB)': 281.5, 'Mem. Infer (MB)': 557.84375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_13/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_13.pkl\n",
      "SEED 14\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  565.140625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8899521531100478, 'F1 Score': 0.8900860061198823, 'F0.75 Score': 0.8902508109818372, 'Precision': 0.8909204003775203, 'Recall': 0.8899521531100478, 'Training time': 11.161149024963379, 'Inference time': 0.01851797103881836, 'Mem. Train (MB)': 236.34375, 'Mem. Infer (MB)': 565.140625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8899521531100478, 'F1 Score': 0.8900860061198823, 'F0.75 Score': 0.8902508109818372, 'Precision': 0.8909204003775203, 'Recall': 0.8899521531100478, 'Training time': 11.161149024963379, 'Inference time': 0.01851797103881836, 'Mem. Train (MB)': 236.34375, 'Mem. Infer (MB)': 565.140625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_14/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_14.pkl\n",
      "SEED 15\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  561.109375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8911483253588517, 'F1 Score': 0.890913730529508, 'F0.75 Score': 0.8909506802667364, 'Precision': 0.8912570404062127, 'Recall': 0.8911483253588517, 'Training time': 19.26760482788086, 'Inference time': 0.02609705924987793, 'Mem. Train (MB)': 277.6875, 'Mem. Infer (MB)': 561.109375}\n",
      "Inference time: 0.03 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8911483253588517, 'F1 Score': 0.890913730529508, 'F0.75 Score': 0.8909506802667364, 'Precision': 0.8912570404062127, 'Recall': 0.8911483253588517, 'Training time': 19.26760482788086, 'Inference time': 0.02609705924987793, 'Mem. Train (MB)': 277.6875, 'Mem. Infer (MB)': 561.109375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_15/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_15.pkl\n",
      "SEED 16\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  575.140625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8899521531100478, 'F1 Score': 0.8896753240391435, 'F0.75 Score': 0.8897014741929605, 'Precision': 0.8899849376116693, 'Recall': 0.8899521531100478, 'Training time': 16.022685289382935, 'Inference time': 0.019001245498657227, 'Mem. Train (MB)': 379.90625, 'Mem. Infer (MB)': 575.140625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8899521531100478, 'F1 Score': 0.8896753240391435, 'F0.75 Score': 0.8897014741929605, 'Precision': 0.8899849376116693, 'Recall': 0.8899521531100478, 'Training time': 16.022685289382935, 'Inference time': 0.019001245498657227, 'Mem. Train (MB)': 379.90625, 'Mem. Infer (MB)': 575.140625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_16/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_16.pkl\n",
      "SEED 17\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  588.359375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8917525985785231, 'F0.75 Score': 0.892072209902432, 'Precision': 0.8939620415055384, 'Recall': 0.8923444976076556, 'Training time': 15.079441785812378, 'Inference time': 0.017796754837036133, 'Mem. Train (MB)': 311.390625, 'Mem. Infer (MB)': 588.359375}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8917525985785231, 'F0.75 Score': 0.892072209902432, 'Precision': 0.8939620415055384, 'Recall': 0.8923444976076556, 'Training time': 15.079441785812378, 'Inference time': 0.017796754837036133, 'Mem. Train (MB)': 311.390625, 'Mem. Infer (MB)': 588.359375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_17/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_17.pkl\n",
      "SEED 18\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  592.234375\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8995215311004785, 'F1 Score': 0.8991068671011743, 'F0.75 Score': 0.8991317725317782, 'Precision': 0.8994945283341996, 'Recall': 0.8995215311004785, 'Training time': 15.002323865890503, 'Inference time': 0.01936626434326172, 'Mem. Train (MB)': 395.265625, 'Mem. Infer (MB)': 592.234375}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8995215311004785, 'F1 Score': 0.8991068671011743, 'F0.75 Score': 0.8991317725317782, 'Precision': 0.8994945283341996, 'Recall': 0.8995215311004785, 'Training time': 15.002323865890503, 'Inference time': 0.01936626434326172, 'Mem. Train (MB)': 395.265625, 'Mem. Infer (MB)': 592.234375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_18/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_18.pkl\n",
      "SEED 19\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95/val_embeddings.csv\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/quantized_inference.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  594.90625\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8919056085863919, 'F0.75 Score': 0.8919703787370276, 'Precision': 0.8925135356488515, 'Recall': 0.8923444976076556, 'Training time': 23.751507997512817, 'Inference time': 0.02244114875793457, 'Mem. Train (MB)': 433.328125, 'Mem. Infer (MB)': 594.90625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 302, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8919056085863919, 'F0.75 Score': 0.8919703787370276, 'Precision': 0.8925135356488515, 'Recall': 0.8923444976076556, 'Training time': 23.751507997512817, 'Inference time': 0.02244114875793457, 'Mem. Train (MB)': 433.328125, 'Mem. Infer (MB)': 594.90625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/seed_19/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model_19.pkl\n",
      "/Users/sebasmos/Documents/VE_paper/qnet/graphics.py:102: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(5, 4))\n",
      "Metrics for all seeds: \n",
      "   EMB_size_out  Accuracy  ...  Mem. Train (MB)  Mem. Infer (MB)\n",
      "0           302  0.897129  ...       378.968750       372.703125\n",
      "0           302  0.893541  ...       204.296875       427.062500\n",
      "0           302  0.885167  ...       344.203125       451.140625\n",
      "0           302  0.892344  ...       402.015625       463.031250\n",
      "0           302  0.895933  ...       497.406250       449.890625\n",
      "0           302  0.885167  ...       475.531250       474.281250\n",
      "0           302  0.881579  ...       400.687500       490.656250\n",
      "0           302  0.883971  ...       307.140625       505.421875\n",
      "0           302  0.891148  ...       242.718750       506.937500\n",
      "0           302  0.892344  ...       283.203125       517.828125\n",
      "0           302  0.883971  ...       300.937500       529.156250\n",
      "0           302  0.894737  ...       309.546875       542.375000\n",
      "0           302  0.889952  ...       398.843750       547.812500\n",
      "0           302  0.894737  ...       281.500000       557.843750\n",
      "0           302  0.889952  ...       236.343750       565.140625\n",
      "0           302  0.891148  ...       277.687500       561.109375\n",
      "0           302  0.889952  ...       379.906250       575.140625\n",
      "0           302  0.892344  ...       311.390625       588.359375\n",
      "0           302  0.899522  ...       395.265625       592.234375\n",
      "0           302  0.892344  ...       433.328125       594.906250\n",
      "\n",
      "[20 rows x 10 columns]\n",
      "Consolidated metrics saved at /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/consolidated_metrics_mlp.csv\n",
      "Average and standard deviation metrics saved at /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95_quantized_model/average_metrics_mlp.csv\n",
      "   F1 Score_mean  F1 Score_std  ...  Mem. Infer (MB)_mean  Mem. Infer (MB)_std\n",
      "0       0.890422      0.004707  ...            515.651562             61.24031\n",
      "\n",
      "[1 rows x 8 columns]\n",
      "Evaluation across different seeds completed. Results saved to the output directory.\n"
     ]
    }
   ],
   "source": [
    "# !python quantized_inference.py \\\n",
    "#     --data_path \"/Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64\" \\\n",
    "#     --total_num_seed 20 \\\n",
    "#     --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results\"\n",
    "\n",
    "!python quantized_inference.py \\\n",
    "    --data_path \"/Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95\" \\\n",
    "    --total_num_seed 20 \\\n",
    "    --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54dd3593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95/seed_0/best_model.pth\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_2_quantized_model/calc_qflops.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "[W130 10:38:16.488700000 qlinear_dynamic.cpp:250] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  0       \n",
      "fwd MACs:                                                               0 MACs  \n",
      "fwd FLOPs:                                                              2.693 KFLOPS\n",
      "fwd+bwd MACs:                                                           0 MACs  \n",
      "fwd+bwd FLOPs:                                                          8.079 KFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "SClassifier(\n",
      "  0 = 0% Params, 0 MACs = 0% MACs, 2.69 KFLOPS = 100% FLOPs\n",
      "  (fc_layers): Sequential(\n",
      "    0 = 0% Params, 0 MACs = 0% MACs, 2.69 KFLOPS = 99.8143% FLOPs\n",
      "    (0): DynamicQuantizedLinear(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=302, out_features=256, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (1): LayerNorm(0 = 0% Params, 0 MACs = 0% MACs, 1.28 KFLOPS = 47.5306% FLOPs, (256,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 256 FLOPS = 9.5061% FLOPs)\n",
      "    (3): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
      "    (4): DynamicQuantizedLinear(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=256, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (5): LayerNorm(0 = 0% Params, 0 MACs = 0% MACs, 640 FLOPS = 23.7653% FLOPs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "    (6): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 128 FLOPS = 4.7531% FLOPs)\n",
      "    (7): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
      "    (8): DynamicQuantizedLinear(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=128, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (9): LayerNorm(0 = 0% Params, 0 MACs = 0% MACs, 320 FLOPS = 11.8827% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\n",
      "    (10): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 64 FLOPS = 2.3765% FLOPs)\n",
      "    (11): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
      "  )\n",
      "  (output_layer): DynamicQuantizedLinear(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=5, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (activation_fn): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  (softmax): Softmax(0 = 0% Params, 0 MACs = 0% MACs, 5 FLOPS = 0.1857% FLOPs, dim=1)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "{'KFLOPS': 2.693, 'KMACS': 0.0, 'KPARAMS': 0.0}\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA/mlp_efficientnet_b3_1536_bs64_PCA0.95/seed_0/flops_results.csv\n",
      "   KFLOPS  KMACS  KPARAMS\n",
      "0   2.693    0.0      0.0\n"
     ]
    }
   ],
   "source": [
    "# !python calc_qflops.py \\\n",
    "#     --data_path \"/Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64\" \\\n",
    "#     --seed_folder 0 \\\n",
    "#     --num_classes 5 \\\n",
    "#     --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results\"\n",
    "\n",
    "# PCA\n",
    "!python calc_qflops.py \\\n",
    "    --data_path \"/Users/sebasmos/Documents/VE_paper/data/urban8k_efficientnet_b3_PCA/efficientnet_b3_1536_bs64_PCA0.95\" \\\n",
    "    --seed_folder 0 \\\n",
    "    --num_classes 5 \\\n",
    "    --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results_urban8k_efficientnet_b3_PCA\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARF_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
