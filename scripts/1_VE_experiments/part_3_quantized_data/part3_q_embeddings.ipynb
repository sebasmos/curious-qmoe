{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using pre-quantized embeddings as data (stored in int8), dequantizing them on-the-fly during data loading. This saves memory bandwidth and storage, allowing larger batches or faster data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 0\n",
      "--------------------------------\n",
      "Train data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/train_embeddings.csv\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "output_folder:  /Users/sebasmos/Documents/VE_paper/1_VE_experiments/BORRAR/mlp_efficientnet_b3_1536_bs64_quantized_VE\n",
      "experiment_folder:  mlp_efficientnet_b3_1536_bs64_quantized_VE\n",
      "Data shape:  (7488, 1536) (7488,)\n",
      "Data shape:  (836, 1536) (836,)\n",
      "---------------------Embeddings shapes----------------------\n",
      "Reset trainable parameters of layer = Linear(in_features=1536, out_features=256, bias=True)\n",
      "Reset trainable parameters of layer = LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=256, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=64, bias=True)\n",
      "Reset trainable parameters of layer = LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=64, out_features=5, bias=True)\n",
      "Starting epoch 1/3\n",
      "Epoch 1/3, F1 Score: 0.7342439957564626\n",
      "Starting epoch 2/3\n",
      "Epoch 2/3, F1 Score: 0.7508789508533941\n",
      "Starting epoch 3/3\n",
      "Epoch 3/3, F1 Score: 0.7805647216546607\n",
      "model_memory_train:  747.8125\n",
      "F1 on eval data:  0.7805647216546607\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/BORRAR/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_0/training_results.json\n"
     ]
    }
   ],
   "source": [
    "!python q_data_trainer.py \\\n",
    "    --data_path \"/Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64\" \\\n",
    "    --num_epochs 300 \\\n",
    "    --total_num_seed 20 \\\n",
    "    --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 0\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  441.203125\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8981287912361051, 'F0.75 Score': 0.8982014808058043, 'Precision': 0.8986577408980791, 'Recall': 0.8983253588516746, 'Training time': 59.127679109573364, 'Inference time': 0.012910842895507812, 'Mem. Train (MB)': 861.796875, 'Mem. Infer (MB)': 441.203125}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8983253588516746, 'F1 Score': 0.8981287912361051, 'F0.75 Score': 0.8982014808058043, 'Precision': 0.8986577408980791, 'Recall': 0.8983253588516746, 'Training time': 59.127679109573364, 'Inference time': 0.012910842895507812, 'Mem. Train (MB)': 861.796875, 'Mem. Infer (MB)': 441.203125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_0/mlp_efficientnet_b3_1536_bs64_quantized_VE_0.pkl\n",
      "SEED 1\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  520.0625\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9019138755980861, 'F1 Score': 0.9012672215246784, 'F0.75 Score': 0.9013975976850016, 'Precision': 0.9024046109878755, 'Recall': 0.9019138755980861, 'Training time': 31.146009922027588, 'Inference time': 0.015443801879882812, 'Mem. Train (MB)': 1060.015625, 'Mem. Infer (MB)': 520.0625}\n",
      "Inference time: 0.02 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9019138755980861, 'F1 Score': 0.9012672215246784, 'F0.75 Score': 0.9013975976850016, 'Precision': 0.9024046109878755, 'Recall': 0.9019138755980861, 'Training time': 31.146009922027588, 'Inference time': 0.015443801879882812, 'Mem. Train (MB)': 1060.015625, 'Mem. Infer (MB)': 520.0625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_1/mlp_efficientnet_b3_1536_bs64_quantized_VE_1.pkl\n",
      "SEED 2\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  562.171875\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9055023923444976, 'F1 Score': 0.9053153944420919, 'F0.75 Score': 0.9052966462930325, 'Precision': 0.9053153277531922, 'Recall': 0.9055023923444976, 'Training time': 43.45640277862549, 'Inference time': 0.01445913314819336, 'Mem. Train (MB)': 1114.171875, 'Mem. Infer (MB)': 562.171875}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9055023923444976, 'F1 Score': 0.9053153944420919, 'F0.75 Score': 0.9052966462930325, 'Precision': 0.9053153277531922, 'Recall': 0.9055023923444976, 'Training time': 43.45640277862549, 'Inference time': 0.01445913314819336, 'Mem. Train (MB)': 1114.171875, 'Mem. Infer (MB)': 562.171875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_2/mlp_efficientnet_b3_1536_bs64_quantized_VE_2.pkl\n",
      "SEED 3\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  590.734375\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8971291866028708, 'F1 Score': 0.8968099467769889, 'F0.75 Score': 0.8967854542911995, 'Precision': 0.8968569294834071, 'Recall': 0.8971291866028708, 'Training time': 41.91749882698059, 'Inference time': 0.01270914077758789, 'Mem. Train (MB)': 1212.578125, 'Mem. Infer (MB)': 590.734375}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8971291866028708, 'F1 Score': 0.8968099467769889, 'F0.75 Score': 0.8967854542911995, 'Precision': 0.8968569294834071, 'Recall': 0.8971291866028708, 'Training time': 41.91749882698059, 'Inference time': 0.01270914077758789, 'Mem. Train (MB)': 1212.578125, 'Mem. Infer (MB)': 590.734375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_3/mlp_efficientnet_b3_1536_bs64_quantized_VE_3.pkl\n",
      "SEED 4\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  614.9375\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8971291866028708, 'F1 Score': 0.89685788315391, 'F0.75 Score': 0.8968657798039754, 'Precision': 0.8970581874698339, 'Recall': 0.8971291866028708, 'Training time': 33.90393280982971, 'Inference time': 0.01387786865234375, 'Mem. Train (MB)': 1225.328125, 'Mem. Infer (MB)': 614.9375}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8971291866028708, 'F1 Score': 0.89685788315391, 'F0.75 Score': 0.8968657798039754, 'Precision': 0.8970581874698339, 'Recall': 0.8971291866028708, 'Training time': 33.90393280982971, 'Inference time': 0.01387786865234375, 'Mem. Train (MB)': 1225.328125, 'Mem. Infer (MB)': 614.9375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_4/mlp_efficientnet_b3_1536_bs64_quantized_VE_4.pkl\n",
      "SEED 5\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  632.71875\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9066985645933014, 'F1 Score': 0.9065388191285353, 'F0.75 Score': 0.9067982436394626, 'Precision': 0.9080863797542784, 'Recall': 0.9066985645933014, 'Training time': 38.7930850982666, 'Inference time': 0.011832714080810547, 'Mem. Train (MB)': 1233.640625, 'Mem. Infer (MB)': 632.71875}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9066985645933014, 'F1 Score': 0.9065388191285353, 'F0.75 Score': 0.9067982436394626, 'Precision': 0.9080863797542784, 'Recall': 0.9066985645933014, 'Training time': 38.7930850982666, 'Inference time': 0.011832714080810547, 'Mem. Train (MB)': 1233.640625, 'Mem. Infer (MB)': 632.71875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_5/mlp_efficientnet_b3_1536_bs64_quantized_VE_5.pkl\n",
      "SEED 6\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  654.53125\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9007177033492823, 'F1 Score': 0.9005186100055864, 'F0.75 Score': 0.9004928733975788, 'Precision': 0.9004868453899215, 'Recall': 0.9007177033492823, 'Training time': 52.3086838722229, 'Inference time': 0.012339115142822266, 'Mem. Train (MB)': 1248.390625, 'Mem. Infer (MB)': 654.53125}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9007177033492823, 'F1 Score': 0.9005186100055864, 'F0.75 Score': 0.9004928733975788, 'Precision': 0.9004868453899215, 'Recall': 0.9007177033492823, 'Training time': 52.3086838722229, 'Inference time': 0.012339115142822266, 'Mem. Train (MB)': 1248.390625, 'Mem. Infer (MB)': 654.53125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_6/mlp_efficientnet_b3_1536_bs64_quantized_VE_6.pkl\n",
      "SEED 7\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  679.4375\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.90311004784689, 'F1 Score': 0.9030944700792739, 'F0.75 Score': 0.903180274704434, 'Precision': 0.9035892262488429, 'Recall': 0.90311004784689, 'Training time': 57.41681790351868, 'Inference time': 0.013157129287719727, 'Mem. Train (MB)': 1066.484375, 'Mem. Infer (MB)': 679.4375}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.90311004784689, 'F1 Score': 0.9030944700792739, 'F0.75 Score': 0.903180274704434, 'Precision': 0.9035892262488429, 'Recall': 0.90311004784689, 'Training time': 57.41681790351868, 'Inference time': 0.013157129287719727, 'Mem. Train (MB)': 1066.484375, 'Mem. Infer (MB)': 679.4375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_7/mlp_efficientnet_b3_1536_bs64_quantized_VE_7.pkl\n",
      "SEED 8\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  697.578125\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.90311004784689, 'F1 Score': 0.9028663440855026, 'F0.75 Score': 0.9028863307113422, 'Precision': 0.9031213809602054, 'Recall': 0.90311004784689, 'Training time': 36.40489315986633, 'Inference time': 0.011324167251586914, 'Mem. Train (MB)': 1139.109375, 'Mem. Infer (MB)': 697.578125}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.90311004784689, 'F1 Score': 0.9028663440855026, 'F0.75 Score': 0.9028863307113422, 'Precision': 0.9031213809602054, 'Recall': 0.90311004784689, 'Training time': 36.40489315986633, 'Inference time': 0.011324167251586914, 'Mem. Train (MB)': 1139.109375, 'Mem. Infer (MB)': 697.578125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_8/mlp_efficientnet_b3_1536_bs64_quantized_VE_8.pkl\n",
      "SEED 9\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  711.296875\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8995215311004785, 'F1 Score': 0.8996743783082671, 'F0.75 Score': 0.8997460661954149, 'Precision': 0.8999879600653381, 'Recall': 0.8995215311004785, 'Training time': 28.601886749267578, 'Inference time': 0.01190805435180664, 'Mem. Train (MB)': 1163.9375, 'Mem. Infer (MB)': 711.296875}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8995215311004785, 'F1 Score': 0.8996743783082671, 'F0.75 Score': 0.8997460661954149, 'Precision': 0.8999879600653381, 'Recall': 0.8995215311004785, 'Training time': 28.601886749267578, 'Inference time': 0.01190805435180664, 'Mem. Train (MB)': 1163.9375, 'Mem. Infer (MB)': 711.296875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_9/mlp_efficientnet_b3_1536_bs64_quantized_VE_9.pkl\n",
      "SEED 10\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  733.328125\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9090909090909091, 'F1 Score': 0.9093276827950374, 'F0.75 Score': 0.9094541851039117, 'Precision': 0.9098970235314582, 'Recall': 0.9090909090909091, 'Training time': 38.00841689109802, 'Inference time': 0.012009143829345703, 'Mem. Train (MB)': 1194.359375, 'Mem. Infer (MB)': 733.328125}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9090909090909091, 'F1 Score': 0.9093276827950374, 'F0.75 Score': 0.9094541851039117, 'Precision': 0.9098970235314582, 'Recall': 0.9090909090909091, 'Training time': 38.00841689109802, 'Inference time': 0.012009143829345703, 'Mem. Train (MB)': 1194.359375, 'Mem. Infer (MB)': 733.328125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_10/mlp_efficientnet_b3_1536_bs64_quantized_VE_10.pkl\n",
      "SEED 11\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  746.59375\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9078947368421053, 'F1 Score': 0.9075578772477002, 'F0.75 Score': 0.9075419165950737, 'Precision': 0.9076591209187126, 'Recall': 0.9078947368421053, 'Training time': 47.99787402153015, 'Inference time': 0.012099027633666992, 'Mem. Train (MB)': 1204.625, 'Mem. Infer (MB)': 746.59375}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9078947368421053, 'F1 Score': 0.9075578772477002, 'F0.75 Score': 0.9075419165950737, 'Precision': 0.9076591209187126, 'Recall': 0.9078947368421053, 'Training time': 47.99787402153015, 'Inference time': 0.012099027633666992, 'Mem. Train (MB)': 1204.625, 'Mem. Infer (MB)': 746.59375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_11/mlp_efficientnet_b3_1536_bs64_quantized_VE_11.pkl\n",
      "SEED 12\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  770.046875\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9007177033492823, 'F1 Score': 0.9008218978039918, 'F0.75 Score': 0.9008672867985615, 'Precision': 0.9010168504274264, 'Recall': 0.9007177033492823, 'Training time': 37.00007081031799, 'Inference time': 0.013837099075317383, 'Mem. Train (MB)': 1147.0625, 'Mem. Infer (MB)': 770.046875}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9007177033492823, 'F1 Score': 0.9008218978039918, 'F0.75 Score': 0.9008672867985615, 'Precision': 0.9010168504274264, 'Recall': 0.9007177033492823, 'Training time': 37.00007081031799, 'Inference time': 0.013837099075317383, 'Mem. Train (MB)': 1147.0625, 'Mem. Infer (MB)': 770.046875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_12/mlp_efficientnet_b3_1536_bs64_quantized_VE_12.pkl\n",
      "SEED 13\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  770.546875\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8918990043397107, 'F0.75 Score': 0.8918448016948152, 'Precision': 0.891850577363797, 'Recall': 0.8923444976076556, 'Training time': 42.30257511138916, 'Inference time': 0.012028932571411133, 'Mem. Train (MB)': 1183.140625, 'Mem. Infer (MB)': 770.546875}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8923444976076556, 'F1 Score': 0.8918990043397107, 'F0.75 Score': 0.8918448016948152, 'Precision': 0.891850577363797, 'Recall': 0.8923444976076556, 'Training time': 42.30257511138916, 'Inference time': 0.012028932571411133, 'Mem. Train (MB)': 1183.140625, 'Mem. Infer (MB)': 770.546875}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_13/mlp_efficientnet_b3_1536_bs64_quantized_VE_13.pkl\n",
      "SEED 14\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  773.75\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9066985645933014, 'F1 Score': 0.9065105159253122, 'F0.75 Score': 0.9064757594015098, 'Precision': 0.9064226087256751, 'Recall': 0.9066985645933014, 'Training time': 54.24337100982666, 'Inference time': 0.027554035186767578, 'Mem. Train (MB)': 1184.75, 'Mem. Infer (MB)': 773.75}\n",
      "Inference time: 0.03 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9066985645933014, 'F1 Score': 0.9065105159253122, 'F0.75 Score': 0.9064757594015098, 'Precision': 0.9064226087256751, 'Recall': 0.9066985645933014, 'Training time': 54.24337100982666, 'Inference time': 0.027554035186767578, 'Mem. Train (MB)': 1184.75, 'Mem. Infer (MB)': 773.75}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_14/mlp_efficientnet_b3_1536_bs64_quantized_VE_14.pkl\n",
      "SEED 15\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  781.78125\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8995215311004785, 'F1 Score': 0.8996061216681261, 'F0.75 Score': 0.8996618886042382, 'Precision': 0.8998682097031998, 'Recall': 0.8995215311004785, 'Training time': 35.811294078826904, 'Inference time': 0.01474308967590332, 'Mem. Train (MB)': 1077.890625, 'Mem. Infer (MB)': 781.78125}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.8995215311004785, 'F1 Score': 0.8996061216681261, 'F0.75 Score': 0.8996618886042382, 'Precision': 0.8998682097031998, 'Recall': 0.8995215311004785, 'Training time': 35.811294078826904, 'Inference time': 0.01474308967590332, 'Mem. Train (MB)': 1077.890625, 'Mem. Infer (MB)': 781.78125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_15/mlp_efficientnet_b3_1536_bs64_quantized_VE_15.pkl\n",
      "SEED 16\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  785.34375\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9066985645933014, 'F1 Score': 0.9066315554687352, 'F0.75 Score': 0.9066386691544482, 'Precision': 0.9067088084380932, 'Recall': 0.9066985645933014, 'Training time': 32.08673810958862, 'Inference time': 0.012980937957763672, 'Mem. Train (MB)': 1079.953125, 'Mem. Infer (MB)': 785.34375}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9066985645933014, 'F1 Score': 0.9066315554687352, 'F0.75 Score': 0.9066386691544482, 'Precision': 0.9067088084380932, 'Recall': 0.9066985645933014, 'Training time': 32.08673810958862, 'Inference time': 0.012980937957763672, 'Mem. Train (MB)': 1079.953125, 'Mem. Infer (MB)': 785.34375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_16/mlp_efficientnet_b3_1536_bs64_quantized_VE_16.pkl\n",
      "SEED 17\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  792.9375\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9055023923444976, 'F1 Score': 0.9051739150402983, 'F0.75 Score': 0.9052018494588872, 'Precision': 0.9055181069224396, 'Recall': 0.9055023923444976, 'Training time': 36.44200897216797, 'Inference time': 0.01258707046508789, 'Mem. Train (MB)': 1104.71875, 'Mem. Infer (MB)': 792.9375}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9055023923444976, 'F1 Score': 0.9051739150402983, 'F0.75 Score': 0.9052018494588872, 'Precision': 0.9055181069224396, 'Recall': 0.9055023923444976, 'Training time': 36.44200897216797, 'Inference time': 0.01258707046508789, 'Mem. Train (MB)': 1104.71875, 'Mem. Infer (MB)': 792.9375}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_17/mlp_efficientnet_b3_1536_bs64_quantized_VE_17.pkl\n",
      "SEED 18\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  805.078125\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9043062200956937, 'F1 Score': 0.9042149039324398, 'F0.75 Score': 0.9042380425685191, 'Precision': 0.9043955296912429, 'Recall': 0.9043062200956937, 'Training time': 51.46135926246643, 'Inference time': 0.013298988342285156, 'Mem. Train (MB)': 1009.640625, 'Mem. Infer (MB)': 805.078125}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9043062200956937, 'F1 Score': 0.9042149039324398, 'F0.75 Score': 0.9042380425685191, 'Precision': 0.9043955296912429, 'Recall': 0.9043062200956937, 'Training time': 51.46135926246643, 'Inference time': 0.013298988342285156, 'Mem. Train (MB)': 1009.640625, 'Mem. Infer (MB)': 805.078125}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_18/mlp_efficientnet_b3_1536_bs64_quantized_VE_18.pkl\n",
      "SEED 19\n",
      "--------------------------------\n",
      "Val data: /Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64/val_embeddings.csv\n",
      "Data shape:  (836, 1536) (836,)\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/q_data_inference.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "total_cpu_memory_inference (MB):  808.40625\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9066985645933014, 'F1 Score': 0.9064670036147647, 'F0.75 Score': 0.9064716298792034, 'Precision': 0.9066223697348111, 'Recall': 0.9066985645933014, 'Training time': 51.89726424217224, 'Inference time': 0.011558055877685547, 'Mem. Train (MB)': 1084.296875, 'Mem. Infer (MB)': 808.40625}\n",
      "Inference time: 0.01 seconds\n",
      "{'EMB_size_out': 1536, 'Accuracy': 0.9066985645933014, 'F1 Score': 0.9064670036147647, 'F0.75 Score': 0.9064716298792034, 'Precision': 0.9066223697348111, 'Recall': 0.9066985645933014, 'Training time': 51.89726424217224, 'Inference time': 0.011558055877685547, 'Mem. Train (MB)': 1084.296875, 'Mem. Infer (MB)': 808.40625}\n",
      "Model saved in: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_19/mlp_efficientnet_b3_1536_bs64_quantized_VE_19.pkl\n",
      "/Users/sebasmos/Documents/VE_paper/qnet/graphics.py:102: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(5, 4))\n",
      "Metrics for all seeds: \n",
      "   EMB_size_out  Accuracy  ...  Mem. Train (MB)  Mem. Infer (MB)\n",
      "0          1536  0.898325  ...       861.796875       441.203125\n",
      "0          1536  0.901914  ...      1060.015625       520.062500\n",
      "0          1536  0.905502  ...      1114.171875       562.171875\n",
      "0          1536  0.897129  ...      1212.578125       590.734375\n",
      "0          1536  0.897129  ...      1225.328125       614.937500\n",
      "0          1536  0.906699  ...      1233.640625       632.718750\n",
      "0          1536  0.900718  ...      1248.390625       654.531250\n",
      "0          1536  0.903110  ...      1066.484375       679.437500\n",
      "0          1536  0.903110  ...      1139.109375       697.578125\n",
      "0          1536  0.899522  ...      1163.937500       711.296875\n",
      "0          1536  0.909091  ...      1194.359375       733.328125\n",
      "0          1536  0.907895  ...      1204.625000       746.593750\n",
      "0          1536  0.900718  ...      1147.062500       770.046875\n",
      "0          1536  0.892344  ...      1183.140625       770.546875\n",
      "0          1536  0.906699  ...      1184.750000       773.750000\n",
      "0          1536  0.899522  ...      1077.890625       781.781250\n",
      "0          1536  0.906699  ...      1079.953125       785.343750\n",
      "0          1536  0.905502  ...      1104.718750       792.937500\n",
      "0          1536  0.904306  ...      1009.640625       805.078125\n",
      "0          1536  0.906699  ...      1084.296875       808.406250\n",
      "\n",
      "[20 rows x 10 columns]\n",
      "Consolidated metrics saved at /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/consolidated_metrics_mlp.csv\n",
      "Average and standard deviation metrics saved at /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/average_metrics_mlp.csv\n",
      "   F1 Score_mean  F1 Score_std  ...  Mem. Infer (MB)_mean  Mem. Infer (MB)_std\n",
      "0       0.902464       0.00445  ...            693.624219           104.596632\n",
      "\n",
      "[1 rows x 8 columns]\n",
      "Evaluation across different seeds completed. Results saved to the output directory.\n"
     ]
    }
   ],
   "source": [
    "!python q_data_inference.py \\\n",
    "    --data_path \"/Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64\" \\\n",
    "    --total_num_seed 20 \\\n",
    "    --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (836, 1536) (836,)\n",
      "Loading model from: /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_0/best_model.pth\n",
      "/Users/sebasmos/Documents/VE_paper/1_VE_experiments/part_3_quantized_data/calc_flops.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  0       \n",
      "fwd MACs:                                                               434.496 KMACs\n",
      "fwd FLOPs:                                                              871.685 KFLOPS\n",
      "fwd+bwd MACs:                                                           1.3035 MMACs\n",
      "fwd+bwd FLOPs:                                                          2.6151 MFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "SClassifier(\n",
      "  0 = 0% Params, 434.5 KMACs = 100% MACs, 871.68 KFLOPS = 100% FLOPs\n",
      "  (fc_layers): Sequential(\n",
      "    0 = 0% Params, 434.18 KMACs = 99.9264% MACs, 871.04 KFLOPS = 99.926% FLOPs\n",
      "    (0): Linear(0 = 0% Params, 393.22 KMACs = 90.4993% MACs, 786.43 KFLOPS = 90.2197% FLOPs, in_features=1536, out_features=256, bias=True)\n",
      "    (1): LayerNorm(0 = 0% Params, 0 MACs = 0% MACs, 1.28 KFLOPS = 0.1468% FLOPs, (256,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 256 FLOPS = 0.0294% FLOPs)\n",
      "    (3): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
      "    (4): Linear(0 = 0% Params, 32.77 KMACs = 7.5416% MACs, 65.54 KFLOPS = 7.5183% FLOPs, in_features=256, out_features=128, bias=True)\n",
      "    (5): LayerNorm(0 = 0% Params, 0 MACs = 0% MACs, 640 FLOPS = 0.0734% FLOPs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "    (6): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 128 FLOPS = 0.0147% FLOPs)\n",
      "    (7): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
      "    (8): Linear(0 = 0% Params, 8.19 KMACs = 1.8854% MACs, 16.38 KFLOPS = 1.8796% FLOPs, in_features=128, out_features=64, bias=True)\n",
      "    (9): LayerNorm(0 = 0% Params, 0 MACs = 0% MACs, 320 FLOPS = 0.0367% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\n",
      "    (10): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 64 FLOPS = 0.0073% FLOPs)\n",
      "    (11): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
      "  )\n",
      "  (output_layer): Linear(0 = 0% Params, 320 MACs = 0.0736% MACs, 640 FLOPS = 0.0734% FLOPs, in_features=64, out_features=5, bias=True)\n",
      "  (activation_fn): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  (softmax): Softmax(0 = 0% Params, 0 MACs = 0% MACs, 5 FLOPS = 0.0006% FLOPs, dim=1)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "{'KFLOPS': 871.685, 'KMACS': 434.496, 'KPARAMS': 0.0}\n",
      "Results saved to /Users/sebasmos/Documents/VE_paper/1_VE_experiments/results/mlp_efficientnet_b3_1536_bs64_quantized_VE/seed_0/flops_results.csv\n",
      "    KFLOPS    KMACS  KPARAMS\n",
      "0  871.685  434.496      0.0\n"
     ]
    }
   ],
   "source": [
    "!python calc_flops.py \\\n",
    "    --data_path \"/Users/sebasmos/Documents/VE_paper/data/efficientnet_b3_1536_bs64\" \\\n",
    "    --seed_folder 0 \\\n",
    "    --num_classes 5 \\\n",
    "    --output_dir \"/Users/sebasmos/Documents/VE_paper/1_VE_experiments/results\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARF_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
