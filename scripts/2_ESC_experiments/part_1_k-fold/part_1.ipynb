{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945eeede-ef0f-4983-82d9-edb10f928c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=256, bias=True)\n",
      "Reset trainable parameters of layer = LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=256, out_features=128, bias=True)\n",
      "Reset trainable parameters of layer = LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=128, out_features=64, bias=True)\n",
      "Reset trainable parameters of layer = LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=64, out_features=6, bias=True)\n",
      "------------> [384 192 224 384 160  96 160] 1600 [0 1 2 3 4 5 6]\n",
      "Starting epoch 1/2\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebastian/codes/repo_clean/VE_paper/2_ESC_experiments/part_1_baseline/part_1_k_fold_val.py\", line 173, in <module>\n",
      "    main(args)\n",
      "  File \"/home/sebastian/codes/repo_clean/VE_paper/2_ESC_experiments/part_1_baseline/part_1_k_fold_val.py\", line 109, in main\n",
      "    model_trained, train_losses, val_losses, f1 = train_pytorch(args, model, train_loader, val_loader, class_weights, num_columns, args.device, fold_dir)\n",
      "                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebastian/codes/repo_clean/VE_paper/qnet/train.py\", line 57, in train_pytorch\n",
      "    loss = criterion(outputs, labels)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebastian/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebastian/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebastian/anaconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py\", line 1293, in forward\n",
      "    return F.cross_entropy(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebastian/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py\", line 3479, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: weight tensor should be defined either for all 6 classes or no classes but got weight tensor of shape: [7]\n"
     ]
    }
   ],
   "source": [
    "!python part_1_k_fold_val.py \\\n",
    "    --data_path /home/sebastian/codes/repo_clean/VE_paper/0_VE_extraction/part0_ESC-VE-extraction/efficientnet_b3_16_bs64 \\\n",
    "    --num_epochs 2 \\\n",
    "    --model mlp \\\n",
    "    --num_classes 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARF_paper",
   "language": "python",
   "name": "arf_paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
